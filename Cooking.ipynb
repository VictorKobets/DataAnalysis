{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза «мешка слов». Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать «мешком ингредиентов», потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные «темы». Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (cuisine) и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cuisine': u'greek', u'id': 10259, u'ingredients': [u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print recipes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(recipes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая, и целиком помещается в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть полезная переменная dictionary.token2id, позволяющая находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. \n",
    "\n",
    "\n",
    "Затем вызовите метод модели *show_topics*, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода *show_topics* указать параметр *formatted=True*, то топы ингредиентов будет удобно выводить на печать, если *formatted=False*, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 29s, sys: 2.75 s, total: 6min 31s\n",
      "Wall time: 6min 38s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "%time LDA_model = models.ldamodel.LdaModel(corpus = corpus, id2word = dictionary, num_topics = 40, passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = LDA_model.show_topics(num_topics = 40, num_words = 10, formatted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.089*\"cooking spray\" + 0.083*\"salt\" + 0.080*\"garlic cloves\" + 0.068*\"olive oil\" + 0.066*\"chopped onion\" + 0.037*\"crushed red pepper\" + 0.036*\"fat free less sodium chicken broth\" + 0.034*\"black pepper\" + 0.032*\"ground black pepper\" + 0.032*\"water\"'),\n",
       " (1,\n",
       "  u'0.085*\"carrots\" + 0.059*\"onions\" + 0.057*\"sauce\" + 0.056*\"cabbage\" + 0.046*\"spinach\" + 0.039*\"beef\" + 0.033*\"low sodium chicken broth\" + 0.033*\"water\" + 0.029*\"firm tofu\" + 0.028*\"green cabbage\"'),\n",
       " (2,\n",
       "  u'0.066*\"cracked black pepper\" + 0.059*\"dry red wine\" + 0.041*\"shortening\" + 0.041*\"beef broth\" + 0.040*\"vegetable oil cooking spray\" + 0.039*\"grape tomatoes\" + 0.035*\"cilantro sprigs\" + 0.031*\"french bread\" + 0.029*\"dried rosemary\" + 0.029*\"all-purpose flour\"'),\n",
       " (3,\n",
       "  u'0.133*\"potatoes\" + 0.124*\"oil\" + 0.063*\"salt\" + 0.059*\"chickpeas\" + 0.042*\"onions\" + 0.038*\"coriander\" + 0.034*\"pepper\" + 0.033*\"saffron\" + 0.031*\"chopped tomatoes\" + 0.026*\"vegetables\"'),\n",
       " (4,\n",
       "  u'0.062*\"green bell pepper\" + 0.058*\"garlic powder\" + 0.056*\"cayenne pepper\" + 0.053*\"salt\" + 0.044*\"paprika\" + 0.035*\"onions\" + 0.035*\"dried thyme\" + 0.032*\"worcestershire sauce\" + 0.027*\"onion powder\" + 0.027*\"ground black pepper\"'),\n",
       " (5,\n",
       "  u'0.077*\"ground cumin\" + 0.052*\"salt\" + 0.048*\"ground coriander\" + 0.036*\"onions\" + 0.036*\"olive oil\" + 0.033*\"garlic\" + 0.028*\"paprika\" + 0.026*\"tumeric\" + 0.023*\"cayenne pepper\" + 0.022*\"garlic cloves\"'),\n",
       " (6,\n",
       "  u'0.107*\"ground cinnamon\" + 0.087*\"ground nutmeg\" + 0.056*\"honey\" + 0.047*\"ground allspice\" + 0.046*\"raisins\" + 0.046*\"ground cloves\" + 0.044*\"light brown sugar\" + 0.031*\"ground ginger\" + 0.030*\"brown sugar\" + 0.030*\"margarine\"'),\n",
       " (7,\n",
       "  u'0.085*\"zucchini\" + 0.080*\"plum tomatoes\" + 0.077*\"fresh basil\" + 0.074*\"olive oil\" + 0.047*\"eggplant\" + 0.039*\"salt\" + 0.031*\"grated parmesan cheese\" + 0.030*\"garlic cloves\" + 0.030*\"red bell pepper\" + 0.029*\"spaghetti\"'),\n",
       " (8,\n",
       "  u'0.087*\"rice\" + 0.077*\"cooking oil\" + 0.067*\"salt\" + 0.059*\"water\" + 0.051*\"basmati rice\" + 0.049*\"vinegar\" + 0.046*\"ginger\" + 0.036*\"curry leaves\" + 0.029*\"mint leaves\" + 0.023*\"red cabbage\"'),\n",
       " (9,\n",
       "  u'0.079*\"dried oregano\" + 0.073*\"onions\" + 0.061*\"garlic\" + 0.057*\"tomato sauce\" + 0.053*\"salt\" + 0.050*\"ground beef\" + 0.049*\"diced tomatoes\" + 0.043*\"dried basil\" + 0.040*\"tomato paste\" + 0.035*\"olive oil\"'),\n",
       " (10,\n",
       "  u'0.049*\"white wine\" + 0.048*\"ground black pepper\" + 0.037*\"butter\" + 0.036*\"russet potatoes\" + 0.031*\"chopped fresh chives\" + 0.030*\"kosher salt\" + 0.027*\"red potato\" + 0.027*\"ham\" + 0.026*\"large eggs\" + 0.024*\"salt\"'),\n",
       " (11,\n",
       "  u'0.067*\"jalapeno chilies\" + 0.064*\"salt\" + 0.051*\"avocado\" + 0.042*\"lime\" + 0.035*\"purple onion\" + 0.034*\"garlic\" + 0.032*\"olive oil\" + 0.032*\"fresh cilantro\" + 0.031*\"cilantro\" + 0.029*\"lime juice\"'),\n",
       " (12,\n",
       "  u'0.134*\"cucumber\" + 0.070*\"lean ground beef\" + 0.046*\"cider vinegar\" + 0.045*\"feta cheese\" + 0.040*\"lemon wedge\" + 0.039*\"romaine lettuce\" + 0.035*\"cream\" + 0.034*\"cherry tomatoes\" + 0.031*\"chili\" + 0.027*\"taco seasoning mix\"'),\n",
       " (13,\n",
       "  u'0.086*\"sour cream\" + 0.056*\"salsa\" + 0.049*\"shredded cheddar cheese\" + 0.048*\"flour tortillas\" + 0.041*\"chili powder\" + 0.039*\"black beans\" + 0.034*\"green onions\" + 0.031*\"ground cumin\" + 0.026*\"corn tortillas\" + 0.024*\"cheddar cheese\"'),\n",
       " (14,\n",
       "  u'0.111*\"white sugar\" + 0.086*\"sweet potatoes\" + 0.058*\"fresh mint\" + 0.050*\"black peppercorns\" + 0.045*\"fennel seeds\" + 0.037*\"red wine\" + 0.032*\"vegetable stock\" + 0.024*\"sugar\" + 0.023*\"maple syrup\" + 0.022*\"garlic chili sauce\"'),\n",
       " (15,\n",
       "  u'0.090*\"cold water\" + 0.072*\"cinnamon sticks\" + 0.057*\"boiling water\" + 0.044*\"sugar\" + 0.041*\"star anise\" + 0.033*\"slivered almonds\" + 0.029*\"cake flour\" + 0.027*\"panko breadcrumbs\" + 0.026*\"green olives\" + 0.024*\"apple cider vinegar\"'),\n",
       " (16,\n",
       "  u'0.101*\"extra-virgin olive oil\" + 0.060*\"garlic cloves\" + 0.050*\"olive oil\" + 0.046*\"flat leaf parsley\" + 0.039*\"freshly ground pepper\" + 0.039*\"fresh lemon juice\" + 0.038*\"salt\" + 0.036*\"dry white wine\" + 0.032*\"large garlic cloves\" + 0.029*\"ground black pepper\"'),\n",
       " (17,\n",
       "  u'0.140*\"coconut milk\" + 0.054*\"parsley\" + 0.048*\"thyme\" + 0.045*\"chicken thighs\" + 0.035*\"garlic\" + 0.033*\"coconut oil\" + 0.033*\"onions\" + 0.025*\"Thai red curry paste\" + 0.024*\"bread\" + 0.020*\"salt\"'),\n",
       " (18,\n",
       "  u'0.103*\"salt\" + 0.090*\"all-purpose flour\" + 0.087*\"eggs\" + 0.085*\"milk\" + 0.070*\"butter\" + 0.055*\"baking powder\" + 0.050*\"sugar\" + 0.040*\"flour\" + 0.034*\"baking soda\" + 0.030*\"buttermilk\"'),\n",
       " (19,\n",
       "  u'0.135*\"curry powder\" + 0.071*\"frozen peas\" + 0.065*\"long-grain rice\" + 0.053*\"sweetened condensed milk\" + 0.046*\"greek yogurt\" + 0.038*\"egg whites\" + 0.032*\"cauliflower\" + 0.030*\"cardamom pods\" + 0.028*\"black-eyed peas\" + 0.026*\"ground cayenne pepper\"'),\n",
       " (20,\n",
       "  u'0.044*\"peanut oil\" + 0.042*\"ground white pepper\" + 0.035*\"beansprouts\" + 0.035*\"Sriracha\" + 0.032*\"rice noodles\" + 0.032*\"medium shrimp\" + 0.030*\"peanuts\" + 0.025*\"minced ginger\" + 0.025*\"fish sauce\" + 0.024*\"english cucumber\"'),\n",
       " (21,\n",
       "  u'0.116*\"boneless skinless chicken breast halves\" + 0.107*\"coarse salt\" + 0.067*\"ground pepper\" + 0.060*\"sweet onion\" + 0.055*\"mayonaise\" + 0.042*\"pork tenderloin\" + 0.040*\"minced garlic\" + 0.038*\"juice\" + 0.035*\"minced onion\" + 0.031*\"dried parsley\"'),\n",
       " (22,\n",
       "  u'0.080*\"diced onions\" + 0.054*\"lettuce\" + 0.054*\"self rising flour\" + 0.048*\"provolone cheese\" + 0.032*\"iceberg lettuce\" + 0.028*\"frozen pastry puff sheets\" + 0.026*\"romano cheese\" + 0.025*\"semi-sweet chocolate morsels\" + 0.024*\"shredded cheese\" + 0.024*\"reduced-fat sour cream\"'),\n",
       " (23,\n",
       "  u'0.186*\"lemon juice\" + 0.092*\"dijon mustard\" + 0.051*\"creole seasoning\" + 0.040*\"white pepper\" + 0.039*\"fresh orange juice\" + 0.038*\"nutmeg\" + 0.029*\"kale\" + 0.028*\"mayonaise\" + 0.028*\"salmon fillets\" + 0.027*\"cream cheese, soften\"'),\n",
       " (24,\n",
       "  u'0.082*\"sugar\" + 0.072*\"whipping cream\" + 0.057*\"orange juice\" + 0.054*\"hot water\" + 0.050*\"chopped garlic\" + 0.049*\"orange\" + 0.033*\"bananas\" + 0.030*\"bread flour\" + 0.029*\"water\" + 0.029*\"brandy\"'),\n",
       " (25,\n",
       "  u'0.066*\"salt\" + 0.063*\"cumin seed\" + 0.054*\"onions\" + 0.045*\"ground turmeric\" + 0.041*\"garam masala\" + 0.041*\"green chilies\" + 0.040*\"clove\" + 0.031*\"chili powder\" + 0.031*\"tomatoes\" + 0.028*\"oil\"'),\n",
       " (26,\n",
       "  u'0.084*\"fish sauce\" + 0.046*\"white vinegar\" + 0.042*\"sugar\" + 0.037*\"garlic\" + 0.036*\"lime juice\" + 0.035*\"vegetable oil\" + 0.034*\"shallots\" + 0.030*\"water\" + 0.030*\"lemongrass\" + 0.027*\"red chili peppers\"'),\n",
       " (27,\n",
       "  u'0.103*\"grated parmesan cheese\" + 0.056*\"warm water\" + 0.056*\"salt\" + 0.046*\"shredded mozzarella cheese\" + 0.043*\"olive oil\" + 0.038*\"ricotta cheese\" + 0.037*\"active dry yeast\" + 0.036*\"mozzarella cheese\" + 0.032*\"butter\" + 0.031*\"italian seasoning\"'),\n",
       " (28,\n",
       "  u'0.199*\"shrimp\" + 0.057*\"pork\" + 0.055*\"baby spinach\" + 0.034*\"jasmine rice\" + 0.033*\"unsweetened coconut milk\" + 0.033*\"fresh tomatoes\" + 0.032*\"noodles\" + 0.031*\"black mustard seeds\" + 0.028*\"sausage casings\" + 0.025*\"sea scallops\"'),\n",
       " (29,\n",
       "  u'0.134*\"mushrooms\" + 0.082*\"white wine vinegar\" + 0.048*\"shallots\" + 0.042*\"boneless chicken breast\" + 0.034*\"olive oil\" + 0.033*\"chopped fresh sage\" + 0.027*\"butter\" + 0.026*\"chorizo sausage\" + 0.026*\"blanched almonds\" + 0.024*\"chicken drumsticks\"'),\n",
       " (30,\n",
       "  u'0.089*\"large eggs\" + 0.088*\"unsalted butter\" + 0.067*\"sugar\" + 0.057*\"salt\" + 0.054*\"all-purpose flour\" + 0.050*\"heavy cream\" + 0.038*\"whole milk\" + 0.033*\"vanilla extract\" + 0.033*\"granulated sugar\" + 0.029*\"large egg yolks\"'),\n",
       " (31,\n",
       "  u'0.071*\"salt\" + 0.063*\"ground red pepper\" + 0.052*\"water\" + 0.052*\"finely chopped onion\" + 0.046*\"chopped celery\" + 0.032*\"green beans\" + 0.031*\"hot pepper sauce\" + 0.031*\"long grain white rice\" + 0.030*\"chopped onion\" + 0.028*\"chopped green bell pepper\"'),\n",
       " (32,\n",
       "  u'0.063*\"water\" + 0.060*\"fine sea salt\" + 0.050*\"lemon zest\" + 0.049*\"fresh spinach\" + 0.041*\"yukon gold potatoes\" + 0.036*\"sesame seeds\" + 0.034*\"collard greens\" + 0.032*\"parmigiano reggiano cheese\" + 0.031*\"rice flour\" + 0.029*\"tofu\"'),\n",
       " (33,\n",
       "  u'0.133*\"balsamic vinegar\" + 0.070*\"dark soy sauce\" + 0.066*\"chopped fresh mint\" + 0.063*\"baguette\" + 0.051*\"broccoli\" + 0.031*\"penne\" + 0.031*\"mint\" + 0.028*\"tequila\" + 0.019*\"red kidney beans\" + 0.018*\"arugula\"'),\n",
       " (34,\n",
       "  u'0.089*\"onions\" + 0.074*\"salt\" + 0.059*\"garlic\" + 0.049*\"olive oil\" + 0.041*\"bay leaves\" + 0.041*\"ground black pepper\" + 0.038*\"chicken stock\" + 0.037*\"pepper\" + 0.037*\"carrots\" + 0.032*\"chicken\"'),\n",
       " (35,\n",
       "  u'0.097*\"soy sauce\" + 0.052*\"sesame oil\" + 0.042*\"sugar\" + 0.042*\"corn starch\" + 0.039*\"garlic\" + 0.035*\"green onions\" + 0.035*\"scallions\" + 0.034*\"rice vinegar\" + 0.029*\"salt\" + 0.028*\"water\"'),\n",
       " (36,\n",
       "  u'0.109*\"cheese\" + 0.064*\"garlic salt\" + 0.061*\"rice wine\" + 0.058*\"chives\" + 0.043*\"chicken breast halves\" + 0.041*\"shredded sharp cheddar cheese\" + 0.040*\"roasted peanuts\" + 0.039*\"Mexican cheese blend\" + 0.037*\"non-fat sour cream\" + 0.034*\"dashi\"'),\n",
       " (37,\n",
       "  u'0.180*\"chicken broth\" + 0.101*\"chicken breasts\" + 0.062*\"onions\" + 0.053*\"crushed red pepper flakes\" + 0.053*\"garlic\" + 0.041*\"pepper\" + 0.038*\"chopped parsley\" + 0.035*\"salt\" + 0.034*\"olive oil\" + 0.025*\"bay leaf\"'),\n",
       " (38,\n",
       "  u'0.064*\"olive oil\" + 0.060*\"red wine vinegar\" + 0.054*\"salt\" + 0.045*\"parmesan cheese\" + 0.041*\"garlic\" + 0.040*\"fresh basil leaves\" + 0.037*\"extra-virgin olive oil\" + 0.031*\"pepper\" + 0.030*\"ground black pepper\" + 0.030*\"tomatoes\"'),\n",
       " (39,\n",
       "  u'0.101*\"canola oil\" + 0.066*\"fresh lime juice\" + 0.063*\"chopped cilantro fresh\" + 0.058*\"kosher salt\" + 0.054*\"garlic cloves\" + 0.034*\"peeled fresh ginger\" + 0.030*\"chiles\" + 0.029*\"vegetable oil\" + 0.028*\"serrano chile\" + 0.026*\"boneless chicken skinless thigh\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mushrooms', 1), ('eggs', 1), ('sugar', 7), ('water', 8), ('chicken', 1), ('salt', 20)]\n"
     ]
    }
   ],
   "source": [
    "top_word = {'salt': 0,\n",
    "        'sugar': 0,\n",
    "        'water': 0,\n",
    "        'mushrooms': 0,\n",
    "        'chicken': 0,\n",
    "        'eggs': 0}\n",
    "\n",
    "for tema in topics:\n",
    "    super_dictionary = tema[1].split('\"')\n",
    "    for word in super_dictionary:\n",
    "        if word == 'salt':\n",
    "            top_word['salt'] += 1\n",
    "        elif word == 'sugar':\n",
    "            top_word['sugar'] += 1\n",
    "        elif word == 'water':\n",
    "            top_word['water'] += 1\n",
    "        elif word == 'mushrooms':\n",
    "            top_word['mushrooms'] += 1\n",
    "        elif word == 'chicken':\n",
    "            top_word['chicken'] += 1\n",
    "        elif word == 'eggs':\n",
    "            top_word['eggs'] += 1\n",
    "            \n",
    "print top_word.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_salt = top_word['salt']\n",
    "c_sugar = top_word['sugar']\n",
    "c_water = top_word['water']\n",
    "c_mushrooms = top_word['mushrooms']\n",
    "c_chicken = top_word['chicken']\n",
    "c_eggs = top_word['eggs']\n",
    "\n",
    "save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами — фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)\n",
    "dictionary3 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная *dfs* — это словарь, ключами которого являются id токена, а элементами — число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря *filter_tokens*, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after — размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after — суммарное количество ингредиентов в корпусе (для каждого документа вычислите число различных ингредиентов в нем и просуммируйте по всем документам) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_dictionary_token = dictionary2.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "popular_ingredients = []\n",
    "for key in super_dictionary_token:\n",
    "    if super_dictionary_token[key] > 4000:\n",
    "        popular_ingredients.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 9, 12, 17, 21, 29, 45, 48, 54, 100, 117]\n"
     ]
    }
   ],
   "source": [
    "print popular_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_dictionary_token_after = dictionary3.filter_tokens(popular_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(6714 unique tokens: [u'low-sodium fat-free chicken broth', u'sweetened coconut', u'baking chocolate', u'egg roll wrappers', u'bottled low sodium salsa']...)\n",
      "\n",
      "\n",
      "Dictionary(6702 unique tokens: [u'low-sodium fat-free chicken broth', u'sweetened coconut', u'baking chocolate', u'egg roll wrappers', u'bottled low sodium salsa']...)\n"
     ]
    }
   ],
   "source": [
    "print dictionary2\n",
    "print '\\n'\n",
    "print dictionary3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size_before = 6714\n",
    "\n",
    "dict_size_after = 6702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = [dictionary3.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_size_before = 0\n",
    "corpus_size_after = 0\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    corpus_size_before += len(corpus[i])\n",
    "    \n",
    "for i in range(len(corpus2)):\n",
    "    corpus_size_after += len(corpus2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictionary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом *top_topics* модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 43s, sys: 2.13 s, total: 5min 45s\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "%time LDA_model_three = models.ldamodel.LdaModel(corpus = corpus2, id2word = dictionary2, num_topics = 40, passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens_kogerentnost_1 = LDA_model.top_topics(corpus)\n",
    "top_tokens_kogerentnost_2 = LDA_model_three.top_topics(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence = 0\n",
    "coherence2 = 0\n",
    "for i in range(len(top_tokens_kogerentnost_1)):\n",
    "    coherence += (top_tokens_kogerentnost_1[i][1]) / (len(top_tokens_kogerentnost_1))\n",
    "    coherence2 += (top_tokens_kogerentnost_2[i][1]) / (len(top_tokens_kogerentnost_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers3(coherence, coherence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом *get_document_topics* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = corpus2[0]\n",
    "topics = LDA_model_three.get_document_topics(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.628124999999999), (21, 0.1281249999999998), (23, 0.1281249999999998)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной *.alpha* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n"
     ]
    }
   ],
   "source": [
    "alph = LDA_model_three.alpha\n",
    "print alph[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте про фиксацию seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром *minimum_probability=0.01* и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 38s, sys: 4.37 s, total: 15min 42s\n",
      "Wall time: 15min 49s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "%time LDA_model_four = models.ldamodel.LdaModel(corpus = corpus2, id2word = dictionary2, num_topics = 40, passes = 5, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_new = corpus2[0]\n",
    "topics = LDA_model_four.get_document_topics(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.021277839257091438),\n",
       " (1, 0.0212774673062234),\n",
       " (2, 0.021347106807850815),\n",
       " (3, 0.081907574816906),\n",
       " (4, 0.021356758592252747),\n",
       " (5, 0.02127666833823671),\n",
       " (6, 0.021282718723840098),\n",
       " (7, 0.02135216402312965),\n",
       " (8, 0.02129786490147947),\n",
       " (9, 0.021352985398777447),\n",
       " (10, 0.04287766455814259),\n",
       " (11, 0.02132748672299583),\n",
       " (12, 0.02485503670412019),\n",
       " (13, 0.042004222151580776),\n",
       " (14, 0.021413296498939225),\n",
       " (15, 0.021293211612785534),\n",
       " (16, 0.02127661178856046),\n",
       " (17, 0.04256778678254317),\n",
       " (18, 0.04047927743144199),\n",
       " (19, 0.021276843849255423),\n",
       " (20, 0.021646643569864902),\n",
       " (21, 0.021302723365674694),\n",
       " (22, 0.0212890679694442),\n",
       " (23, 0.021330066265674984),\n",
       " (24, 0.021284779751625755),\n",
       " (25, 0.02127659574468085),\n",
       " (26, 0.021299416174953047),\n",
       " (27, 0.021286663303279947),\n",
       " (28, 0.02141167992142519),\n",
       " (29, 0.02127659574468085),\n",
       " (30, 0.021276595744695273),\n",
       " (31, 0.02127659574468085),\n",
       " (32, 0.021419567804785985),\n",
       " (33, 0.02128930620347274),\n",
       " (34, 0.021398849209141143),\n",
       " (35, 0.0215608962729313),\n",
       " (36, 0.021300134191353057),\n",
       " (37, 0.021371869042106688),\n",
       " (38, 0.021321991666565104),\n",
       " (39, 0.02127937604281046)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202005\n",
      "\n",
      "\n",
      "1590960\n"
     ]
    }
   ],
   "source": [
    "count_model2_list = []\n",
    "count_model3_list = []\n",
    "\n",
    "for i in range(len(corpus2)):\n",
    "    list_topics_2 = LDA_model_three.get_document_topics(corpus2[i], minimum_probability = 0.01)\n",
    "    count_model2_list.append(len(list_topics_2))\n",
    "    \n",
    "    list_topics_3 = LDA_model_four.get_document_topics(corpus2[i], minimum_probability = 0.01)\n",
    "    count_model3_list.append(len(list_topics_3))\n",
    "    \n",
    "count_model2 = sum(count_model2_list)\n",
    "count_model3 = sum(count_model3_list)\n",
    "\n",
    "print(count_model2)\n",
    "print '\\n'\n",
    "print(count_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers4(count_model2, count_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр __alpha__ влияет на разреженность распределений тем в документах. Аналогично гиперпараметр __eta__ влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда, распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for i in range(len(corpus2)):\n",
    "    list_doc = LDA_model_three.get_document_topics(corpus2[i], minimum_probability = 0)\n",
    "    line = []\n",
    "    for j in list_doc:\n",
    "        line.append(j[1])\n",
    "    matrix.append(line)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_names = []\n",
    "for current_recipe_dict in recipes:\n",
    "    cuisine_names.append(current_recipe_dict['cuisine'])\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators = 100, random_state=0)\n",
    "cross_validation_scores = cross_val_score(estimator = random_forest_classifier, X = matrix, y = cuisine_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mean_score = np.mean(cross_validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5507128630436421"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers5(accuracy_mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10–15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA — вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(t, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple schnapps\n",
      "smoked mozzarella\n",
      "pink lady apple\n",
      "mustard powder\n",
      "boneless pork shoulder roast\n"
     ]
    }
   ],
   "source": [
    "generate_recipe(LDA_model_three, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу $A$ размера темы $x$ кухни, ее элементы $a_{tc}$ — суммы $p(t|d)$ по всем документам $d$, которые отнесены к кухне $c$. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу $A$. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>irish</th>\n",
       "      <th>mexican</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>vietnamese</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>japanese</th>\n",
       "      <th>british</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>french</th>\n",
       "      <th>spanish</th>\n",
       "      <th>russian</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>thai</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>korean</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025448</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.049832</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.032601</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.061866</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.032793</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.009160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111878</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>0.019534</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.011790</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>0.037629</td>\n",
       "      <td>0.021579</td>\n",
       "      <td>0.129450</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>0.038591</td>\n",
       "      <td>0.114296</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.107501</td>\n",
       "      <td>0.037038</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.049026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.208524</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.042349</td>\n",
       "      <td>0.036899</td>\n",
       "      <td>0.084946</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.047635</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.034329</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.058176</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>0.005517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>0.015338</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.015020</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>0.115305</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.018812</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.026873</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>0.012522</td>\n",
       "      <td>0.018805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.014011</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.016281</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.035067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.125122</td>\n",
       "      <td>0.019847</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>0.068740</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.025456</td>\n",
       "      <td>0.051926</td>\n",
       "      <td>0.029466</td>\n",
       "      <td>0.151491</td>\n",
       "      <td>0.032662</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.051310</td>\n",
       "      <td>0.061180</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.089590</td>\n",
       "      <td>0.026814</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.092304</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.032383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016957</td>\n",
       "      <td>0.032105</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.041518</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.007592</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.043885</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.055715</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>0.038414</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.101775</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.034328</td>\n",
       "      <td>0.008022</td>\n",
       "      <td>0.050595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007073</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>0.024248</td>\n",
       "      <td>0.014892</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.025630</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.007649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>0.066339</td>\n",
       "      <td>0.093774</td>\n",
       "      <td>0.036387</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>0.023066</td>\n",
       "      <td>0.012439</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.014769</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.005766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.024391</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.031187</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.053149</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.019303</td>\n",
       "      <td>0.019249</td>\n",
       "      <td>0.013903</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.012395</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.040457</td>\n",
       "      <td>0.014970</td>\n",
       "      <td>0.030717</td>\n",
       "      <td>0.007413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.010882</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>0.033765</td>\n",
       "      <td>0.045321</td>\n",
       "      <td>0.019423</td>\n",
       "      <td>0.058117</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>0.037430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010702</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.015473</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.018281</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.018787</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.083621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.212137</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.014328</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.008754</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.010299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.014681</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.030282</td>\n",
       "      <td>0.031597</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.027274</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.018249</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.007219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.144951</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.050350</td>\n",
       "      <td>0.089970</td>\n",
       "      <td>0.020405</td>\n",
       "      <td>0.021789</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.080082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.048664</td>\n",
       "      <td>0.022507</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.023190</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.005482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>0.018396</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.019892</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.022695</td>\n",
       "      <td>0.011030</td>\n",
       "      <td>0.023719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.036046</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>0.028184</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.019466</td>\n",
       "      <td>0.010224</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>0.036823</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.029201</td>\n",
       "      <td>0.012812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.028651</td>\n",
       "      <td>0.034068</td>\n",
       "      <td>0.012718</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.036981</td>\n",
       "      <td>0.017973</td>\n",
       "      <td>0.062818</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.050485</td>\n",
       "      <td>0.026034</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>0.011097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.019935</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.023466</td>\n",
       "      <td>0.051769</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.028758</td>\n",
       "      <td>0.088732</td>\n",
       "      <td>0.014223</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.038057</td>\n",
       "      <td>0.040356</td>\n",
       "      <td>0.040372</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>0.019732</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.030759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.014021</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.008586</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.017545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.013732</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.014818</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>0.007897</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>0.050116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.011577</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.016524</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>0.022628</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.017269</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.018323</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.019950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.107979</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.028869</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.014059</td>\n",
       "      <td>0.051017</td>\n",
       "      <td>0.048180</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.069174</td>\n",
       "      <td>0.044113</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>0.020307</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.029927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>0.202775</td>\n",
       "      <td>0.017818</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>0.017334</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.320609</td>\n",
       "      <td>0.039654</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.016238</td>\n",
       "      <td>0.015497</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.029364</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.004899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>0.037121</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.016865</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.078368</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.029549</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.017506</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.007573</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.023991</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.014791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>0.029225</td>\n",
       "      <td>0.018332</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.036961</td>\n",
       "      <td>0.014410</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.033140</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>0.155603</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.015215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>0.037239</td>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.215294</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.040095</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.043685</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>0.007860</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.224684</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.050531</td>\n",
       "      <td>0.004580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.045351</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.028091</td>\n",
       "      <td>0.013291</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.073581</td>\n",
       "      <td>0.009496</td>\n",
       "      <td>0.045778</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.021917</td>\n",
       "      <td>0.041613</td>\n",
       "      <td>0.019452</td>\n",
       "      <td>0.024921</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.073630</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.013893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.013504</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.083997</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.051837</td>\n",
       "      <td>0.219554</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.031741</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.134432</td>\n",
       "      <td>0.004755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.015168</td>\n",
       "      <td>0.010663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.019711</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.013830</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.019655</td>\n",
       "      <td>0.007747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.011713</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.041583</td>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.029969</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.044857</td>\n",
       "      <td>0.024931</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.011071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.011636</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.017043</td>\n",
       "      <td>0.011099</td>\n",
       "      <td>0.019567</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.012909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.023838</td>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>0.042079</td>\n",
       "      <td>0.040861</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.033405</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>0.023434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>0.016106</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>0.023469</td>\n",
       "      <td>0.018107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.010371</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.255604</td>\n",
       "      <td>0.090630</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.013155</td>\n",
       "      <td>0.111234</td>\n",
       "      <td>0.020223</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.089508</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.306749</td>\n",
       "      <td>0.005873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.027547</td>\n",
       "      <td>0.024560</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>0.017227</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>0.035081</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.057133</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.011876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.007425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       irish   mexican   chinese  filipino  vietnamese  moroccan  brazilian  \\\n",
       "0   0.025448  0.008334  0.008180  0.006170    0.006791  0.049832   0.018264   \n",
       "1   0.111878  0.017568  0.019534  0.019225    0.011790  0.018052   0.037629   \n",
       "2   0.006251  0.208524  0.009038  0.013848    0.042349  0.036899   0.084946   \n",
       "3   0.009648  0.024229  0.008802  0.015338    0.014330  0.021617   0.015020   \n",
       "4   0.010729  0.013911  0.006423  0.004578    0.005844  0.005571   0.005489   \n",
       "5   0.125122  0.019847  0.016851  0.068740    0.010088  0.025456   0.051926   \n",
       "6   0.016957  0.032105  0.010478  0.017728    0.008581  0.041518   0.022500   \n",
       "7   0.007073  0.007311  0.029846  0.024248    0.014892  0.004372   0.025630   \n",
       "8   0.010152  0.009962  0.066339  0.093774    0.036387  0.006530   0.026005   \n",
       "9   0.024391  0.007183  0.031187  0.033761    0.053149  0.009427   0.019303   \n",
       "10  0.035261  0.018484  0.006645  0.005153    0.007731  0.028176   0.013428   \n",
       "11  0.010702  0.006213  0.010654  0.008678    0.006233  0.012344   0.015473   \n",
       "12  0.011439  0.212137  0.003432  0.006835    0.003913  0.007575   0.021764   \n",
       "13  0.006530  0.014681  0.006537  0.011566    0.007671  0.005645   0.009533   \n",
       "14  0.011786  0.022303  0.005823  0.011758    0.007774  0.045794   0.015584   \n",
       "15  0.009237  0.008693  0.048664  0.022507    0.032200  0.006574   0.008853   \n",
       "16  0.016988  0.013187  0.007934  0.008224    0.011748  0.018396   0.017003   \n",
       "17  0.014950  0.005844  0.036046  0.013950    0.028184  0.008770   0.010541   \n",
       "18  0.028651  0.034068  0.012718  0.025238    0.006882  0.009374   0.036981   \n",
       "19  0.019935  0.012953  0.010256  0.014602    0.023466  0.051769   0.019131   \n",
       "20  0.003282  0.008983  0.007649  0.014021    0.012232  0.008151   0.008586   \n",
       "21  0.013732  0.008684  0.010877  0.011622    0.008029  0.006458   0.014818   \n",
       "22  0.011577  0.007771  0.005215  0.004281    0.004957  0.009276   0.016524   \n",
       "23  0.107979  0.012987  0.010764  0.032429    0.013846  0.049258   0.023354   \n",
       "24  0.008159  0.012954  0.007781  0.017547    0.014303  0.202775   0.017818   \n",
       "25  0.009644  0.007885  0.007812  0.011018    0.010609  0.037121   0.011394   \n",
       "26  0.017506  0.004015  0.006050  0.007573    0.005571  0.018821   0.008250   \n",
       "27  0.009724  0.023025  0.029417  0.029225    0.018332  0.012059   0.036961   \n",
       "28  0.004028  0.009244  0.037239  0.062287    0.215294  0.006418   0.040095   \n",
       "29  0.045351  0.011115  0.005790  0.028091    0.013291  0.008932   0.073581   \n",
       "30  0.013504  0.009518  0.083997  0.020821    0.058580  0.005419   0.051837   \n",
       "31  0.005002  0.005837  0.013285  0.009288    0.021278  0.007499   0.007265   \n",
       "32  0.009290  0.012534  0.014920  0.004237    0.019711  0.003959   0.003165   \n",
       "33  0.011713  0.015411  0.010899  0.041583    0.019174  0.029969   0.011120   \n",
       "34  0.011636  0.004083  0.006689  0.008937    0.004037  0.006441   0.004901   \n",
       "35  0.018985  0.006841  0.007979  0.011526    0.011931  0.018313   0.013265   \n",
       "36  0.015535  0.006652  0.003791  0.007101    0.006748  0.020567   0.008123   \n",
       "37  0.010371  0.005301  0.255604  0.090630    0.067138  0.006611   0.013155   \n",
       "38  0.023370  0.020228  0.020637  0.027547    0.024560  0.018727   0.024145   \n",
       "39  0.008847  0.004419  0.008571  0.007468    0.017130  0.017891   0.004755   \n",
       "\n",
       "    japanese   british     greek    indian  jamaican    french   spanish  \\\n",
       "0   0.006828  0.032601  0.016801  0.014063  0.061866  0.018376  0.011081   \n",
       "1   0.021579  0.129450  0.026640  0.022585  0.038591  0.114296  0.041551   \n",
       "2   0.010350  0.004487  0.010098  0.039604  0.047635  0.004532  0.034329   \n",
       "3   0.015853  0.012728  0.115305  0.015151  0.010058  0.018812  0.026813   \n",
       "4   0.002901  0.010802  0.029421  0.004930  0.009326  0.013900  0.014011   \n",
       "5   0.029466  0.151491  0.032662  0.021200  0.051310  0.061180  0.040128   \n",
       "6   0.007592  0.018295  0.043885  0.020753  0.055715  0.019820  0.038414   \n",
       "7   0.013561  0.016510  0.003795  0.002469  0.014648  0.011856  0.011022   \n",
       "8   0.023066  0.012439  0.004776  0.014769  0.034148  0.009337  0.010706   \n",
       "9   0.019249  0.013903  0.004789  0.009658  0.015599  0.009760  0.008024   \n",
       "10  0.005389  0.010882  0.039979  0.015880  0.012830  0.033765  0.045321   \n",
       "11  0.008830  0.018281  0.018878  0.017934  0.004057  0.015572  0.018787   \n",
       "12  0.002413  0.010823  0.014328  0.006677  0.008315  0.008754  0.009977   \n",
       "13  0.013481  0.006915  0.007961  0.030282  0.031597  0.005901  0.012323   \n",
       "14  0.005640  0.009515  0.144951  0.011222  0.006323  0.050350  0.089970   \n",
       "15  0.015674  0.008355  0.007193  0.023190  0.008147  0.005516  0.006720   \n",
       "16  0.010571  0.015250  0.018495  0.007850  0.013058  0.025848  0.019892   \n",
       "17  0.019466  0.010224  0.009334  0.012773  0.015268  0.017560  0.009442   \n",
       "18  0.017973  0.062818  0.010161  0.011383  0.039080  0.010986  0.014971   \n",
       "19  0.012940  0.028758  0.088732  0.014223  0.011968  0.038057  0.040356   \n",
       "20  0.006084  0.004728  0.008207  0.010108  0.007782  0.007597  0.014083   \n",
       "21  0.007728  0.008590  0.017904  0.007897  0.011404  0.009302  0.011033   \n",
       "22  0.007233  0.012554  0.022628  0.030372  0.017269  0.014252  0.012319   \n",
       "23  0.028869  0.044962  0.020799  0.014059  0.051017  0.048180  0.034722   \n",
       "24  0.035843  0.017334  0.011699  0.320609  0.039654  0.013929  0.016238   \n",
       "25  0.016865  0.011575  0.026622  0.012342  0.013688  0.052772  0.078368   \n",
       "26  0.011186  0.012167  0.009263  0.023991  0.003362  0.014098  0.014086   \n",
       "27  0.014410  0.008438  0.013880  0.009953  0.024777  0.008235  0.033140   \n",
       "28  0.032219  0.008289  0.004418  0.016394  0.043685  0.009984  0.007860   \n",
       "29  0.009496  0.045778  0.007705  0.010119  0.021917  0.041613  0.019452   \n",
       "30  0.219554  0.007237  0.005627  0.006800  0.024515  0.009134  0.008996   \n",
       "31  0.008066  0.004199  0.004311  0.005395  0.021918  0.003966  0.007299   \n",
       "32  0.040100  0.005669  0.008997  0.005595  0.002973  0.008373  0.007891   \n",
       "33  0.009574  0.010581  0.013551  0.044857  0.024931  0.015112  0.016201   \n",
       "34  0.010031  0.014111  0.007594  0.017043  0.011099  0.019567  0.007054   \n",
       "35  0.023838  0.018895  0.017610  0.009743  0.013477  0.042079  0.040861   \n",
       "36  0.005872  0.009497  0.014241  0.004007  0.006158  0.027260  0.016106   \n",
       "37  0.111234  0.020223  0.006016  0.011096  0.028611  0.009987  0.004030   \n",
       "38  0.017227  0.014229  0.011908  0.018429  0.035081  0.014435  0.028788   \n",
       "39  0.006574  0.013515  0.006115  0.012434  0.008121  0.014553  0.005124   \n",
       "\n",
       "     russian  cajun_creole      thai  southern_us    korean   italian  \n",
       "0   0.016964      0.010803  0.006369     0.032793  0.003122  0.009160  \n",
       "1   0.107501      0.037038  0.006985     0.139057  0.009753  0.049026  \n",
       "2   0.007760      0.011087  0.058176     0.013594  0.007609  0.005517  \n",
       "3   0.026873      0.016543  0.009145     0.009808  0.012522  0.018805  \n",
       "4   0.007882      0.016281  0.009939     0.013073  0.001995  0.035067  \n",
       "5   0.089590      0.026814  0.007496     0.092304  0.009270  0.032383  \n",
       "6   0.018677      0.101775  0.009546     0.034328  0.008022  0.050595  \n",
       "7   0.017565      0.008488  0.008065     0.013702  0.015687  0.007649  \n",
       "8   0.017101      0.010014  0.027820     0.014790  0.020482  0.005766  \n",
       "9   0.012395      0.009302  0.040457     0.014970  0.030717  0.007413  \n",
       "10  0.019423      0.058117  0.011941     0.031777  0.007528  0.037430  \n",
       "11  0.009332      0.008087  0.014024     0.008903  0.009546  0.083621  \n",
       "12  0.038901      0.010596  0.003982     0.015889  0.005430  0.010299  \n",
       "13  0.018045      0.027274  0.006288     0.018249  0.004256  0.007219  \n",
       "14  0.020405      0.021789  0.008277     0.014121  0.005444  0.080082  \n",
       "15  0.006153      0.009553  0.025124     0.006005  0.013640  0.005482  \n",
       "16  0.018453      0.014522  0.007007     0.022695  0.011030  0.023719  \n",
       "17  0.006307      0.011898  0.036823     0.009878  0.029201  0.012812  \n",
       "18  0.050485      0.026034  0.005947     0.027579  0.011918  0.011097  \n",
       "19  0.040372      0.016586  0.014832     0.019732  0.005664  0.030759  \n",
       "20  0.004033      0.008386  0.013579     0.007672  0.007155  0.017545  \n",
       "21  0.017963      0.014741  0.010742     0.016500  0.014589  0.050116  \n",
       "22  0.018670      0.007817  0.010168     0.018323  0.006393  0.019950  \n",
       "23  0.069174      0.044113  0.009217     0.020307  0.016573  0.029927  \n",
       "24  0.015497      0.006279  0.029364     0.007072  0.004862  0.004899  \n",
       "25  0.028090      0.029549  0.009872     0.013530  0.005426  0.075130  \n",
       "26  0.007211      0.013690  0.005566     0.006776  0.005086  0.014791  \n",
       "27  0.009658      0.155603  0.028603     0.035275  0.010777  0.015215  \n",
       "28  0.006973      0.004753  0.224684     0.008508  0.050531  0.004580  \n",
       "29  0.024921      0.018349  0.010267     0.073630  0.005470  0.013893  \n",
       "30  0.013285      0.008456  0.031741     0.009934  0.134432  0.004755  \n",
       "31  0.008732      0.005246  0.027485     0.006118  0.015168  0.010663  \n",
       "32  0.004808      0.010656  0.013830     0.016477  0.019655  0.007747  \n",
       "33  0.014540      0.009986  0.013994     0.013130  0.009634  0.011071  \n",
       "34  0.013944      0.002859  0.003984     0.006834  0.005882  0.012909  \n",
       "35  0.019260      0.033405  0.012593     0.013081  0.010032  0.023434  \n",
       "36  0.013832      0.012290  0.003580     0.006172  0.023469  0.018107  \n",
       "37  0.011503      0.008971  0.089508     0.009399  0.306749  0.005873  \n",
       "38  0.014492      0.057133  0.029000     0.026667  0.016995  0.011876  \n",
       "39  0.013004      0.004984  0.021443     0.007494  0.008465  0.007425  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Визуализируйте матрицу\n",
    "compute_topic_cuisine_matrix(LDA_model_three, corpus2, recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAJ3CAYAAAB2jz2AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmcZFV9///Xu9fZV2DYF1kkuLA44hoRt6BGMEaDMYorE/WrmGg0+AtfFY0IxiXEoDAuEONKcENFlK8CEhUYRBbZcdgGGBhmhtm6e3qpz++Puj3WtF11+57pul3T9X7yqAc9VfWZc7qmuk7fe855X0UEZmbW3jqmugNmZjb1PBiYmZkHAzMz82BgZmZ4MDAzMzwYmJkZHgzMzAwPBmZmhgcDMzMDuprdwN6Lnlx4i/Pa/k1JbaXspg7K3YF91OKDCtfcvfmhpLY2bu0rXLPv3N2S2lo7sDGpbiQqhWuevfCQpLau27iycE3/0GBSWzO6upPqBoaHCtcMVYaT2kr5t75nw+qktro70z5q+vvvU1JhoqHHVpb2gdC9yxNK/d7y+MjAzMw8GJiZWQmniczMdhqVkanuwZTxkYGZmeUfGUg6FDgB2Cu760Hg4oi4rZkdMzMrXcKChumi4ZGBpH8GvgUIuDa7CfimpFOb3z0zMytD3pHBW4EnRcR2690kfQa4BThzvCJJy4BlAAtm7cHs3kWT0FUzsyar+Migngqw5zj375E9Nq6IWB4RSyNiqQcCM7PWl3dk8A/AzyXdBTyQ3bcvcBDwrmZ2zMysbNHGcwYNB4OIuFTSIcDRbD+BvCIi2ncNlpnZNJO7miiqQ+XVJfTFzGxqec7AzMzaWdN3IJ8y94jCNZ8cvjaprU4VH9sqiUF1qQFmd216sHDNkpkLk9pKeT3+b8+fJbV12siNSXVDCTs+Hxhcn9TWqfOfXrjmq4PFw+0AXt17QFLdtwbuLlzzhw0PJ7V1VucTC9e8oWttUltPWbB/Ul3p2njOwEcGZmbmwcDMzBxUZ2b2Rw6qMzOzduYjAzOzUZ5ALk7SmyezI2ZmNnV25MjgdOD8yeqImdmUa+NNZw0HA0k31XsIWNKgbltq6asWHc0z5hyc3EEzM2u+vCODJcBfAGN3+Qj4db2iiFgOLAf45H6vT9vVZWZWMgfV1fcjYE5E3DD2AUlXNKVHZmZWurzU0rc2eOx1k98dM7Mp1MZzBt5nYGZm3mdgZrZNG88ZKKK587u9M/Yp3MAjJxyU1NYeFxdPmOzpTBsPnzBn96S6wRguXPPsmfsmtfWNR1cUrhkaKd4/gO7E1/HAeXsUrpnV0ZvU1vVriyeC7j8v7d/5/k2PJtV1dXQWrnnm4kOS2lqxvvjrsXV4KP9J46gkfsgObl2lpMJEW+/839IWvPQe8txSv7c8PjIwMxvlbCIzM2tnPjIwMxvVxnMGPjIwM7P8wUDSoZJeKGnOmPuPa163zMxM0nGS7pB0t6RTx3n8BEk3SbpB0nWSnjvR2rEaDgaSTgF+ALwb+L2kE2oePmPi35KZ2U6gUinvlkNSJ3AO8FLgMOBvJR025mk/Bw6PiCOAtwBfKlC7nbw5g5OBp0XEZkn7AxdJ2j8izqaaT1Tvm9gWVNfZtYDOzjn1nmpmZuM7Grg7IlYCSPoWcAJw6+gTImJzzfNnAzHR2rHyBoOO0cYi4l5Jz6c6IOxHg8GgNqguZZ+BmdmUaK0J5L2AB2r+vAp4xtgnSfor4BPAbsDLi9TWypszeETSEaN/yAaGvwR2AZ6SU2tmZnVIWpad5x+9LUv5eyLiexFxKPBK4GOp/ck7MjgJ2G5LakQMAydJOi+1UTOzllRiUF3tGZQ6HgT2qfnz3tl99f6+X0p6gqRditZCzpFBRKyKiNV1HvtVo1ozM9shK4CDJR0gqQd4LXBx7RMkHSRJ2ddHAb3A2onUjuVNZ2ZmmYjWiaOIiGFJ7wJ+CnQCX4mIWyS9PXv8XOCvqZ6pGQL6gROjGjg3bm2j9poeVDd71v6FG1jQOzuprXUDm/OfNI4Znd2FayqkvW4zu3oK16SGg2W/MBQ2nJDP8uHFz05q61/XXV24ZrCSFqY3q7t4wN3MzuL/Xjti89BA4Zr+4cGktjoS3h+dStun2ttV/GcMYM2GO0oNcxu48ZLSFrzMOPxlDqprJSkDwXSWMhCYTRuttZqoVI6jMDMzHxmYmW3jy16amVk785GBmdmoNp4zyB0MJB0NRESsyIKOjgNuj4hLmt47MzMrRcPBQNKHqabedUm6jGq2xeXAqZKOjIiPl9BHM7NytPFqurwjg1cDR1Dd1bYa2DsiNkr6FHANMO5gUJta2tO9iK6uuZPXYzMzm3R5E8jDETESEX3AHyJiI0BE9AN1T65FxPKIWBoRSz0QmJm1vrwjg0FJs7LB4Gmjd0qaT4PBwMxsp+QJ5LqeFxFbASK2e5W6gTc2rVdmZlaqhoPB6EAwzv2PAY81pUdmZlPFm87MzKydNX3TmepfHbOulORGgErC+b4tiW2lJoL2D417sNUUlYRE2hkJqaoA5/Q1TMetK+X17+zoTGprcKR42mlKDaQnzaYkq6akj0JaAmlf4vt3z9mLk+pK18ZzBj4yMDMzx1GYmW3jOQMzM2tnPjIwMxvlI4OJk/TVZnTEzMymTl5Q3cVj7wKOlbQAICKOb1bHzMzKFuGgunr2Bm4FvgQE1cFgKfDpRkXbB9Utptv5RGZmLS3vNNFS4LfAvwAbIuIKoD8iroyIK+sV1QbVeSAws51GpVLercXkxVFUgM9K+p/s/4/k1ZiZ2c5nQh/sEbEKeI2klwMbm9slM7Mp0sY7kAv9lh8RPwZ+3KS+mJnZFPGmMzMz8/l/M7NtWnBityxNHww+u+g5hWtO23RdUlvdCWmWf77giUlt/eyxm5PqFs6YU7jmgJlLktp6cOu6wjVf6Twoqa2TKyuT6hbNLL7a7MDZeyS1NaejeCLow0OPJ7X1vBn7JtVdvPHWwjWpSaJv2/2ZhWuWP/KbpLZG2vhc/M7CRwZmZqPaeNDynIGZmfnIwMxsmzaeM/CRgZmZFTsykPRc4Gjg9xHxs+Z0ycxsinjOYHySrq35+mTgP4G5wIclndrkvpmZWUnyThN113y9DHhxRJwOvAT4u3pFkpZJuk7Sdb/cctckdNPMrARtHFSXNxh0SFooaTHQGRFrACJiCzBcr6g2tfR5sw+exO6amVkz5M0ZzKcaYS0gJO0REQ9LmpPdZ2Y2fbTgb+xlyYuw3r/OQxXgrya9N2ZmNiWS9hlERB9wzyT3xcxsank1kZmZtbOm70D+4MZr8580xsLetEtlPrRlbeGaqx6/I6mtSkRS3eKeeYVr7t7ycFJb6wc2F655dc+WpLb2nb1bUt2mob7CNd1K+x3mho3FD2Z3nbEgqa1vr78hqW7ZwqcVrvn3gV8ntfWTLXcXronE9/1uPfOT6krXxnMGPjIwMzMPBmZm5qA6M7M/8gSymZm1s4ZHBpKeAdwWERslzQROBY4CbgXOiIgNJfTRzKwcnkCu6yvA6HKPs6nuSD4ru+/8JvbLzMxKlDdn0BERoxlESyPiqOzr/5WUtnbOzKxVec6grt9LenP29Y2SlgJIOgQYqldUm1o6MOgzSWZmrS7vyOBtwNmSTgMeA34j6QHggeyxcUXEcmA5wC7zDknbpWJmVrY2njPIC6rbALxJ0jzggOz5qyLikTI6Z2Zm5ZjQPoOI2Ajc2OS+mJlNrTY+MvA+AzMz8w5kM7NtEoP4poOmDwabBwdKqQHYc87iwjVbRwaT2hpJPJy8dd19hWuWzFmY1FZvV3f+k8ZITWO9eW3a5S1SWrtxuO5CtoaGKiOFa7YMpU2PzUh47QE+88ivCtekJok+0r++cM3Mrp6ktn67tnhCqpXLRwZmZqM8Z2BmZu3MRwZmZqN8ZGBmZu2s4WAg6RRJ+5TVGTOzKRWV8m4tJu/I4GPANZKukvROSbuW0SkzMytX3mCwEtib6qDwNOBWSZdKeqOkuletrw2qGxkpflF2MzMrV94EckREBfgZ8DNJ3cBLgb8FPgWMe6RQG1Q3Y8a+7buLw8x2Lm08gZw3GKj2DxExBFwMXCxpVtN6ZWZmpcobDE6s90BE9NV7zMxsp9TGcRQN5wwi4s6yOmJmZlPHm87MzEZ5zqB5OjvK29f2pFl7JdUd1DGncM2lfSuT2lo5/HDhmo7tp24mbFZXb+GaLUNpIYFSWh/ndM8oXLPrzAVJbT2weU3hmo7E7ytVSnu7zJqf1NbGrcXP9PZ0pn1k9A1vTaqz8rT9kUHKQGBm01QbHxk4jsLMzHxkYGa2TQvGRJTFRwZmZuYjAzOzUVFp330GDQcDST3Aa4GHIuL/SXod8GzgNmB5tiPZzMx2cnlHBudnz5kl6Y3AHOC7wAuBo4E3Nrd7ZmYlauPVRHmDwVMi4qmSuoAHgT0jYkTS14Ab6xVJWgYsA+jpXkRXV92AUzMzawF5g0FHdqpoNjALmA+sA3qB7npFtamls2ft374n4cxs59LGq4nyBoMvA7cDncC/AP8jaSXwTOBbTe6bmZmVpOFgEBGflfTt7OuHJH0VeBHwxYi4towOmplZ8+UuLY2Ih2q+fhy4qKk9MjObKm28tNSbzszMrPmbzhb0zi5cs7Z/U1Jbt/Y9lP+kMe5Q2ni4e09aUuS9eqRwTf/IYFJbKVLTR1MNVoYL16zpfzyprZRE0JHEpYaDI8W/L4BKwsVV5ncX/xmDtNTSOd1pFzjckNDWlGjjpaU+MjAzM8dRmJlt4yMDMzNrZz4yMDMblTBnM13kDgaSngC8CtgHGAHuBL4RERub3DczMytJw9NEkk4BzgVmAE+nGkOxD3C1pOc3vXdmZmWqVMq7tZi8I4OTgSOycLrPAJdExPMlnQf8ADhyvKLaoLr5M/dgdu/CyeyzmZlNsonMGXRRPT3USzXCmoi4X9KEgur2Wvik9j0JZ2Y7lzbegZw3GHwJWCHpGuDPgbMAJO1KNb3UzMymgbygurMl/T/gz4BPR8Tt2f1rgOeV0D8zs/I4wrq+iLgFuKWEvpiZ2RTxPgMzs1FtPGfgHchmZi1K0nGS7pB0t6RTx3n87yTdJOlmSb+WdPiYxzsl/U7Sj/LaavqRwdyElMOUJEuAVZvXFK6JxB2H9+vRpLolsxcUrnl865aktvqHthau6emsu0isoUMX7pNUt2rLY4VrRhLP6+41e5fCNfMTUzrv3VI8nRbg6XMPKlxzzbq7ktraY/aiwjUPbCr+MwZw4Pw9kuramaRO4BzgxcAqqot5Lo6IW2uedg9wTESsl/RSqqs4n1Hz+HuA24B5ee35yMDMLBOVSmm3CTgauDsiVkbEINVLDZ+wXX8jfh0R67M/Xg3sPfqYpL2Bl1NdFZrLg4GZ2RSQtEzSdTW3ZWOeshfwQM2fV2X31fNW4Cc1f/534APAhEYeTyCbmY0qcQK5dnPujpJ0LNXB4LnZn/8SeDQifjvR6CAPBmZmrelBqllwo/bO7tuOpKdSPRX00ohYm939HOB4SS+jmi03T9LXIuL19RrzaSIzs1FRKe+WbwVwsKQDJPUArwUurn2CpH2B7wJviIg7t30bER+MiL0jYv+s7heNBgLwkYGZWUuKiGFJ7wJ+CnQCX4mIWyS9PXv8XOBDwGLg89n1y4cjYmlKew0HA0nzgQ8CrwR2AwJ4lGpi6ZkRMe6VyWtTS5fM2Y8FM3dN6ZuZWblabNNZRFwCXDLmvnNrvn4b8Lacv+MK4Iq8tvJOE10IrAeeHxGLImIxcGx234UNGl8eEUsjYqkHAjOz1pd3mmj/iDir9o6IWA2cJektzeuWmdkUaMGLzpQl78jgPkkfkLRk9A5JSyT9M9uvfzUzs51Y3mBwItXJiSslrZO0juq5p0XAa5rcNzOzclWivFuLybuewXrgn7PbdiS9GTi/Sf0yM7MS7cjS0tOZwGDwQEJ43HBlJKU/dHV0Fq6pJAbVVRLD0tYPbC5c06m07SCdCa/HzO6epLYe7k+78F1HdTlcIZu2DiS1tYZxF781tH5wU1JbmwfT+virx24vXNPblRYuuGpz8ZDAzo609+KzZqYFGZbOF7cZn6Sb6j0ELKnzmJmZ7WTyjgyWAH9BdSlpLQG/bkqPzMymSgueyy9L3mDwI2BORNww9gFJVzSlR2ZmVrq8CeS3NnjsdZPfHTMzmwrOJjIzy0zwojPTklNLzcysOUcGtUF1Pd2L6Oqa24xmzMwmVxtPICcfGUj6Sb3HaoPqPBCYmbW+vH0GR9V7CDhi8rtjZjaF2vjIIO800QrgSqof/mMtmPzumJnZVMgbDG4D/j4i7hr7gCSnlprZ9NLGcRR5cwYfafCcd09uV8zMbKrkbTq7qMHDCye5L2ZmU8tzBkkmlFqqcacbGnv0NYek9Iddvl088bEjMYWxkrg5ZZDhwjULZsxOamvTYH/hmv6hwaS2UtMsB4aLt9fVmfa2HRgZKlzTUSn+7wVw4Lw9kuru3fRI4Zq+xITUub2zCtdsTnhPAXzz0euS6r6UVGUpnFpqZpYJHxnU5dRSM7M24NRSM7NRPjIYn1NLzczag1NLzcxGObXUzMzaWcPBQNI8SZ+Q9N+SXjfmsc83qFsm6TpJ1w0Np11Q3MzMypN3ZHA+1ZVD3wFeK+k7knqzx55Zr6g2tbTbqaVmtrOoRHm3FpM3GBwYEadGxPcj4njgeuAXkhaX0DczMytJ3gRyr6SOiGp6U0R8XNKDwC+BOU3vnZlZmVrwN/ay5B0Z/BB4Qe0dEXEB8D4gLbfAzMxaTt4+gw/Uuf9SSWc0p0tmZlMjon2PDJoeVDeUEPS1//fuS+lPUuhcd0faSzDMSFJdJSEvPSVwDmB2z4zCNVuHi4e5AQxX0l6PvebsUrgmJfwQYNXmNYVruju6k9pa3b8uqW7xzOILLlZvGZsWMzEp4YKpH5Yjbbx+f2fhoDozs1FtPGfgoDozM3NQnZnZNj4yGJ+D6szM2oOD6szMMu18cRsH1ZmZmY8MzMy28ZHB+CTtLukLks6RtFjSRyTdLOlCSXWv+F2bWjoysnnye21mZpMq7zTRBcCtwAPA5UA/8DLgKuDcekW1qaWdnY4wMrOdRKXEW4vJGwyWRMTnIuJMYEFEnBURD0TE54D9SuifmZmVIG8wqH38q2Me65zkvpiZ2RTJm0D+gaQ5EbE5Ik4bvVPSQcAdze2amVm52nlpad6msw/Vuf9uST9uTpfMzKxsTU8tTUkFndHVk9If+oa3JtWV6fDFTyhcc/fGh5La2jI0ULimuzPtLfGduXWvgtrQqzddU7gmJQkXYOnigwvXHN5dPFUV4Dvr62U8NrZ1pHhqbGqK6+BI8ddRSmvrxN2fnlRXOh8ZjM+ppWZm7cGppWZmo1pwyWdZnFpqZmZOLTUzG9XOq4kcVGdmZg6qMzPbpo3nDAofGUjabQLP2RZUNzS8Ka1nZmZWmrylpYvG3gVcK+lIQBGxbry6iFgOLAeYM+uA9j0JZ2Y7lXaeM8g7TfQYcN+Y+/YCrgcCKL6DyszMWk7eYPB+4MXA+yPiZgBJ90TEAU3vmZlZ2TxnML6I+DTwNuBDkj4jaS7VIwIzM5tGclcTRcQq4DWSjgcuA2Y1vVdmZlMgfGSQLyIuBo4FXgQg6c3N6pSZmZVLEWlnfSTdHxH75j1v5sz9SjutdPjC4lMZ9/U9mtTWnO6ZSXX3byreXofS9gbOTEh/7R8eTGor9X20eObcwjVr+9OWK1cSfu1LTelM1dVR/JpRC2ekXVp2Td+GwjWpicL9Q2mJwoNbV5X6D7D2FceU9nm1+IdXlvvmyuHUUjOzUW18msippWZm5tRSM7NR7TyB7NRSMzNzUJ2Z2TZtfGTgCGszM2s8GEg6rubr+ZK+LOkmSd+QVHc1UW1q6fDw5snsr5lZ00SlvFuryTsyOKPm608DDwOvAFYA59UriojlEbE0IpZ2daWtgTYzs/IUmTNYGhFHZF9/VtIbm9EhM7Op0oq/sZclbzDYTdJ7qe4rmC9J8cetpp5vMDObJvIGgy8Co3kBFwC7AGsk7Q78yd4DM7OdmY8M6oiI0+vcv1rS5c3pkpmZlW1H9hmcDpyf96TZ3b2F/+LBkeGU/nDDupVJdSk2DfYn1c3rLZ4AnhoClxI6N6OzO6mtrs7iAWuQFjrX05n2tl3QO7twzdaRoaS2KomX/RgeGSlc81jfxqS2Fs0oHhKY+r7fddb8pLrSRUtlx5XKQXVmZuagOjOzUZ4zqM9BdWZmbcBBdWZm5qA6M7NRUWnfCWRvHDMzs+JHBpIWR8TanOcsA5YBzO7djRk9O8myMjNra+08gZyXWnqmpF2yr5dKWglcI+k+ScfUq6sNqvNAYGbW+vJOE708Ih7Lvv434MSIOAh4MdUUUzOzaSNCpd1aTd5g0CVp9FTSzIhYARARdwLFtxabmVlLypsz+DxwiaQzgUslnQ18F3gBDqozs2mmnecM8vYZfE7SzcA7gEOy5x8MfB/4WPO7Z2ZmZchdTRQRVwBXjL1f0puZQFCdmdnOop33GTQ9tXSkUvy4KzUp8gnz9ihcs7pvXVJbKemjAI/2bShc06G0N+ic7hmFazYPDSS1NZD4b5aSQNqptO0xfcNbC9dsGSpeA1BJPN/Q3VH89Thg3u5Jbd2/+dHCNbvNTFsduHageDqtlcuppWZmmcS0+GnBqaVmZubUUjOzUZ4zqMOppWZm7cGppWZmmXY+MnBqqZlZi5J0nKQ7JN0t6dRxHj9U0m8kbZX0T2Me+0dJt0j6vaRvSmq4vDAvqO56SadJOrDgN7BM0nWSrts6lHaxbjOzdiapEzgHeClwGPC3kg4b87R1wCnAp8bU7pXdvzQingx0Aq9t1F7ekcFCYAFwuaRrs5Fmz7xvoja1tLd7Xt7TzcxaQkR5twk4Grg7IlZGxCDwLeCE7fsbj2aZceNt9OkCZmb5crOAhxo1ljcYrI+If4qIfYH3UY2iuF7S5dk1C8zMLEHtGZTsNvYzdS/ggZo/r8ruyxURD1I9WrgfeBjYEBE/a1Qz4TmDiLgqIt6ZdeYs4FkTrTUz2xlEReXdas6gZLflk/V9SFpI9SjiAGBPYLak1zeqyRsM7hx7R0SMRMSlEfHm5J6amVmeB4F9av68d3bfRLwIuCci1kTEENW06Wc3Kmg4GERE3QmHLKjOzGzaaLGL26wADpZ0gKQeqhPAF0/wW7kfeKakWZIEvBC4rVFB04PqFvTOLvwX7zpzQUp/eHDLY/lPGiM1cO6RLY8n1SkhdG7/uWkxUI/0j00Ryfe8xX+W1NYv1zZ8n9VVSQiD2XfOLklt3bvpkcI1Mzq7k9o6dP4++U8ax4P9xd/DKzc+nNTW7rMXFq5Z0+/VgWWJiGFJ7wJ+SnU10Fci4hZJb88eP1fS7sB1wDygIukfgMMi4hpJFwHXA8PA74CGp6EcVGdmlmm1i9tExCXAJWPuO7fm69VUTx+NV/th4MMTbctBdWZm5qA6M7NRlRa8UH1ZHFRnZmYOqjMzGzXBVT7TkoPqzMzMRwZmZqMcYV2HpKVZDtHXJO0j6TJJGyStkHRkg7ptmRubBtZOfq/NzGxS5Z0m+jzwSeDHVJeSnhcR84FTs8fGVZu5MXfG4knrrJlZM7VYammp8gaD7oj4SUR8E4iIuIjqFz8HGl4owczMdh55g8GApJdIeg0Qkl4JIOkYYKTpvTMzs1LkTSC/neppogrVncjvkHQB1eS8k5vbNTOzcnkCuY6IuDEi/iIiXhoRt0fEeyJiQUQ8CXhiSX00M7Mma3pqad/w1sJ/cf/wppT+MJKQMrVlcCCprcUz5ybV7T+reL7fnZsnGmG+vcGR4cI1t/c1vDJeXW/c7eikuq8/9tvCNfdvfjSprf3m7la4plNpW3G2jKS9rzYPFa+b1dWb1NbA8GDhmsGR8a6umG+fhNd+KjiOog6nlpqZtQenlpqZZdo5jsKppWZm5tRSM7NRrbgZrCwOqjMzMwfVmZmNaufVRHlBdXMkfVTSLVlA3RpJV0t6U07dtqC6/sG0C8ebmVl58o4Mvg58j+qKor8BZgPfAk6TdEhE/H/jFUXEcmA5wJL5h7bxWTgz25m082qivDmD/SPigohYFRGfAY6PiLuANwOvan73zMysDHmDwRZJzwWQdDywDiAiKlT3GpiZTRvtHGE9kaC6L0k6GLgFeAuApF2Bc5rcNzMzK0nePoObgD8JnYmINZLSAoTMzFqUVxOlOX3SemFmZlOq6UF16/qLH0B0daZtf4iEE3GVjrSTd5sG+5Pqftt/d+EaKe23lUpCiuuDm9OuWf2VLVcn1XV2FP99ZKRS/PsC+MOGhwvX9HZ1J7XVl5iGm/Le70n8edmwta9wTUdiiuuGwc1JdWVr59VEDqozMzMH1ZmZmYPqzMy28QSymZm1NQfVmZllWnAvWGnygurmSzpT0u2S1klaK+m27L4FZXXSzMyaK+800YVUVxI9PyIWRcRi4NjsvgvrFdWmllYqWyavt2ZmTVQJlXZrNRMJqjsrIlaP3hERqyPiLGC/ekURsTwilkbE0o6O2ZPVVzMza5K8OYP7JH0A+K+IeARA0hLgTcADTe6bmVmp2nnTWd6RwYnAYuBKSeslrQOuABZRvb6BmZlNA3n7DNZLOh+4DLg6IrbtKZd0HHBpk/tnZlaatKCT6SFvNdEpwA+AdwG/l3RCzcNnNLNjZmZWnrw5g5OBp0XEZkn7AxdJ2j8izmaCF7eZ1TOjcKcGR4YL1wB0dXQWrkkNPRuujCTVRcJK5pmdPUlt9Q8PFq7pSAiOA5jd3ZtUtzkh0C3l3xlgJCG4L/X9MX9G2sKJlPaGEt+LsxL+zVLCIAEOnrtXUl3Zoo2v2ZU3GHSMnhqKiHslPZ/qgLAfvtKZmdm0kfdr4COSjhj9QzYw/CWwC/CUZnbMzKxslSjv1mryBoOTgNW1d0TEcEScBDyvab0yM7NS5a0mWtXgsV9NfnfMzKZOpY3Pfju11MzMPBiYmdkODAaSftLgsW1BdYNDG1ObMDMrVaDSbq2m4ZyBpKPqPQQcUecxImI5sBxg/pwDW3De3MzMauXtM1gBXMn4ewp8PQMzm1baOY4ibzAzIt0AAAAgAElEQVS4Dfj7iLhr7AOSnFpqZjZN5A0GH6H+vMK7J7crZmZTqxXP5Zel4QRyRFwESNILJc0Z83DxUBkzM2tJE00tfTdOLTWzaa5S4q3VND21NCWFMTUZcbAyVFpbUtrhZGdC4mZqWym6ExNBuzvy3krj23PO4sI1GwfTrqudku5Z9vsjJWm2MzFpNqVu49a+pLZWbn44qc7K49RSM7NMK/7GXhanlpqZWe6RwUnAdleaiYhh4CRJ5zWtV2ZmU6CdVxM5tdTMzHKPDMzM2kalfQ8McpeWzpP0CUn/Lel1Yx77fHO7ZmZmZcmbQD6f6qqh7wCvlfQdSaNX0X5mvaLa1NKh4U2T1FUzs+aqoNJurSZvMDgwIk6NiO9HxPHA9cAvJDVcHB4RyyNiaUQs7e6aO2mdNTOz5sibM+iV1BERFYCI+LikB4FfAmPjKczMbCeVd2TwQ+AFtXdExAXA+4DiWyXNzFpYlHhrNXlBdR8AVo0NqouIS4FTmt05MzMrR95qondTP6ju483smJlZ2RxUV98ydjCo7oO7Prtwp8567DeFawAqCaFie8xelNTWo/2PJ9UdNn/fwjX39z2a1Nb8nlmFaxb3zEtqa1X/Y0l1aweKXyP7yfP3S2prJIr/CD4+nBaKd9jMPZLq7h1cV7jmtsfTrjPVkbCiZXb3jKS2ZnfPTKqz8jiozswsUykxIbjVOKjOzMwcVGdmNqoVV/mUxUF1ZmbmoDozs1GtuMqnLGnXyzMzs2klb5/B7pK+IOkcSYslfUTSzZIulJS2ds7MrEVVVN6t1eQdGVwA3Ao8AFwO9AMvA64Czq1XVJtaumLz3ZPUVTMza5a8wWBJRHwuIs4EFkTEWRHxQER8Dqi786c2tfTpcw6a1A6bmTWLI6wn9vhXxzzWOcl9MTOzKZK3mugHkuZExOaIOG30TkkHAXc0t2tmZuVq530GeamlHwL2Hie19G7gS83unJmZlWNHUkvPaGbHzMysPE1PLf3YI1cV7lRPZ9peuOHKSOGa9VvLvUbzj5cW39ZyyOVDSW3N655duObeLY8ktTUwnNbH9ff/vHDNkU96XVJbD2xZU7gmJdkT4JG+9Ul1fcNbC9fsmZi8+/CW4n2sJCS/Amwe7E+qK1srLvksi1NLzczMqaVmZqPa+eI2eYPBScDq2jsiYjgiTgKe17RemZlZqZxaamaW8dLSAiTt1oyOmJnZ1Gl4ZCBp7DIFAddKOhJQRBS/YKuZWYvyaqL6HgPuG3PfXsD1VI+onjBekaRlVJel0tW1kM7OOeM9zczMWkTeYPB+4MXA+yPiZgBJ90TEAY2KImI5sBxgxox92/k0nJntRFpxlU9Z8uIoPg28DfiQpM9Imkt7z7GYmU1LuVt9sxVFr5F0PHAZMKvpvTIzmwI+MmhA0qGSXgj8AjgWeFF2/3FN7puZmZUkL6juFGqC6oCXRMTvs4cdVGdm00qovFuryTtNdDI7GFTX2VF4KwODI8OFa1JtHhygq6P4dXoicerkz68eKFyTGgL3SH/xILLU137RjLQVY4v3e1HhGintJ+mp8/cvXLN/1/yktn6ZeLnXhTPmFq5JDcXr7eouXNM/VDxID+Cvd1+aVNfusjMwZ1O9mNiXsqtO1j5+KHA+cBTwLxHxqez+fahekGwJ1Xne5dnndl1tH1SXMhCY2fTUSnMGkjqBc6iu6FwFrJB0cUTcWvO0dcApwCvHlA8D74uI67OFP7+VdNmY2u04qM7MrDUdDdwdESsjYhD4FlB7TRki4tGIWAEMjbn/4Yi4Pvt6E3Ab1T1idTmozsysNe0FPFDz51XkfKCPJzvFfyRwTaPnOajOzCxT5mmi2qSGzPJsw+5ktjEH+A7wDxGxsdFz0y4pZmZmO6Q2qaGOB4F9av68d3bfhEjqpjoQfD0ivpv3/OJLfczMpqko8TYBK4CDJR0gqQd4LXDxRApVXXL3ZeC2iPjMRGry9hkcV/P1fElflnSTpG9IWjKRBszMrLiIGAbeBfyU6gTwhRFxi6S3S3o7gKTdJa0C3gucJmmVpHnAc4A3AC+QdEN2e1mj9vJOE50BXJp9/WngYeAVwKuA8/jT5UxkHdx2LqynexFdXcXXTpuZla3VIqwj4hLgkjH3nVvz9Wqqp4/G+l8KLv8vMmewNCJGl5l+VtIb6z2x9lzY7Fn7O9jOzKzF5Q0Gu0l6L9URZr4kRcToh7vnG8xsWmmlTWdly/tA/yIwF5gDXEB1sxmSdgduaGrPzMysNHn7DE7Psi/2Aq6piaZYLekbZXTQzKwsPjKoQ9K7qUktlVS7FdqppWZm00TenMEydjC1dGZXT+FObRjYUrgGoCMhIXW4MpLUViXSfod4dODxwjUjiW2lJJB2JCaCrulvuLmxrpS000e3FH8NAW7acG/xmqSWYGti0mxKkuhQYtJs6ns/xaVrf5//pBbQzqtd2j611MzMnFpqZrZNReXdWo1TS83MzKmlZmajvJrIzMzaWuHBQNLiZnTEzMymTt4+gzMlje46XippJXCNpPskHdOgbpmk6yRdNzC4YZK7bGbWHC0WYV2qvCODl0fEY9nX/wacGBEHUb1A86frFUXE8ohYGhFLZ/TMn6SumplZs+TtM+iS1JXlas/MLrxMRNwpqbf53TMzK0+lJX9nL0fekcHngUskvQC4VNLZko6RdDoOqjMzmzbylpZ+TtLNwDuAQ7LnHwx8H/jX5nfPzKw87by0dCIXt1lN9UI121JLYdslMS+tW2VmZjuNvNVEp+DUUjNrE+28mijvyOBkdjC1tH94sHCndpmVtgJpRmfxxMdUm4b6k+pS0iyfMG/3pLZWbXks/0ljpCSdAvR0FrmC6h89vrV4Qu2SOQuT2nqsr3iy6r5zd0tq68GE1x7gkjlHFq55/dBdSW31dhZPFH5g85qktqz1ObXUzCzTznMGTi01M7PcI4OTgO3OG2R7Dk6SdF7TemVmNgVaMVq6LE4tNTOzCS0tNTNrC96BXIek6yWdJunAsjpkZmbly5tAXggsAC6XdK2kf5S0Z95fWptaOjy8aVI6ambWbO28zyBvMFgfEf8UEfsC76MaRXG9pMslLatXVJta2tU1dzL7a2ZmTTDhi9tExFUR8U5gL+As4FlN65WZmZUqbwL5zrF3RMQI1Uwi5xKZ2bTiTWd1RMRrJR0q6YWS5tQ+lgXVmZnZNJC3mujdOKjOzNpEhSjt1mryThMtYweD6gYTgtkej+LhZZAW6LZvz6Kktr79krRAt12/fnvhmk5NeGpnO7vNXFC4ZtXmtIC1vsGBpLq5vbMK1+yaeCnV9QOb8580RmowWyXSTjgcu/7qwjVr31E83A5gt/NuKlxz1KK0VeYrHvuTM87WYhxUZ2aWab3f18vjoDozM3NQnZnZqHZeTeSgOjMzc1CdmdmoVlzlU5a0ZSpmZjat5O0zWJrlEH1N0j6SLpO0QdIKSWnr2czMWpSD6ur7PPBJ4MfAr4HzImI+cGr22LhqU0srlbQ9A2ZmVp68waA7In4SEd8EIiIuovrFz4EZ9YpqU0s7OmZPYnfNzJqnUuKt1eQNBgOSXiLpNUBIeiWApGOAkab3zszMSpG3mujtVE8TVYC/AN4h6QLgQeDk5nbNzKxc0ZJn88uRl1p6I/APwKeAVRHxnohYEBFPAuaV0UEzM2u+vNVEpwDfw6mlZmbTWt5popOBpTuSWnr44icU7tTtG+pufG7o7g0PFa7ZPLs/qa29v1U8AROgIyGB9M96lyS19aM1NxSuefLC/ZLaunndvUl1W0eKp9quHlif1NZB83Iv3/2nbfWvS2qruzNtP2fK67H78puT2jp+t+Krw7+3+rqktmZ29ybVla0VJ3bL4tRSMzNzaqmZ2ah2vrhN3mBwErC69o6IGI6Ik4DnNa1XZmZWKqeWmpllWu/39fI4qM7MzHKXls6R9FFJt2QBdWskXS3pTSX1z8ysNJ4zqO/rwEqqu49PB/4DeANwrKS6+wxqg+rW9K2u9zQzM2sReYPB/hFxQUSsiojPAMdHxF3Am4FX1SuqDarbddbuk9lfM7OmcVBdfVskPRdA0vHAOoCIqOB9BmZm00beprN3AF+UdDBwC/BWAEm7Auc0uW9mZqVq56C6vKWlN0p6I7AXcHXNbuQ1ku4so4NmZtZ8Ew2qexcOqjOzaa6d5wyaHlR316bi4XEjkfZSnbT7M5PqLl5fPOjr6QsPSmrrqjW3Fq55aHhTUlur3/RnhWt2/cotSW1VEv/NolL8sLxDadNVd254MKkuRU9iUN3gyHDhmj1nL05qKyXI8L8XHZPU1hvWXZlUZ+Vp+6C6lIHAzKandp4zcFCdmZk5qM7MzBxUZ2a2TStO7JbFQXVmZpY7gWxm1jYq4QnkcUmaL+lMSbdLWidpraTbsvsWlNVJMzNrrrzTRBcC64HnR8SiiFgMHJvdd2G9otrU0sGhjZPXWzOzJooSb61mIqmlZ0XEthVFEbE6Is4C9qtXVJta2tM9b7L6amZmTZI3Z3CfpA8A/xURjwBIWgK8CXigyX0zMytVK150pix5RwYnAouBKyWtl7QOuAJYBPxNk/tmZmYlydtnsF7Sd4CLImKFpCcBxwG3RcS6UnpoZlaSdo6jaDgYSPow8FKgS9JlwNFUjwxOlXRkRHy8+V00M7NmUzRYVyvpZuAIoJdqLMXeEbFR0kzgmoh4al4DPb17Fx5qlZhKOaOrp3BNSkokwPzeWUl1jw9sSaory0hlpNT2Uv6tF82cm9TW2r7iK9s6OzqT2kp9D6e8/nvMWZTU1uot6wvXzOrqTWprsJL2c7al795SAzFP3O+VpR0afPu+77dU2GfenMFwRIxERB/wh4jYCBAR/bT3zm0zs2klbzXRoKRZ2WDwtNE7Jc3Hg4GZTTPtvJoobzB4XkRsBYjY7uol3cAbm9YrMzMrVd5qoq117n8MeKwpPTIzmyLtvJrIqaVmZubBwMzMdmAwkPSTBo9tC6qrjLT2Ukozs1GVEm+tJm/T2VH1HqK6/2BcEbEcWA5p+wzMzKxceauJVgBXUv3wH8vXMzCzaaXRJtzpLm8wuA34+4i4a+wDkpxaamY2TeQNBh+h/rzCuye3K2ZmU6udN501nECOiIuA+ZKeDiDpMEnvlfSyiPh+KT00M7OmK5pa+gzgcpxaambTUCuu8ilL3mmiVzN+aumngGuA3MEgJfWxOzEpsmPcee7GhhNTS1MnmlJSKVMPXA9btG/hmtvXp00FpaZ7prwejyWkjwJ0d+a93f9Umf/OAD2d3YVrHt+atnx7dveMwjWpP5v9w4NJdVaevJ+O4YgYAfokbZdaKqmdB1Ezm4YcR1HfoKTR4H6nlpqZTVNOLTUzy7TzaiKnlpqZWe6RgZlZ22jnHcgN5wwkzZP0CUn/Lel1Yx77fHO7ZmbW3iQdJ+kOSXdLOnWcxyXpP7LHb6rNk5O0QNJFkm6XdJukZzVqK28C+XyquUTfAV4r6TuSRq+I/cwG38C21NLh4c05TZiZtYZWSi2V1AmcQ3Wv12HA30o6bMzTXgocnN2WAV+oeexs4NKIOBQ4nGq8UF15g8GBEXFqRHw/Io4Hrgd+IWlxo6KIWB4RSyNiaVfXnJwmzMxsHEcDd0fEyogYBL4FnDDmOScAX42qq4EFkvbIVnw+D/gyQEQMRsTjjRrLmzPoldQxupIoIj4u6UHgl4A/5c1sWmmxfQZ7AbW7QFdRTYHIe85ewDCwBjhf0uHAb4H3RETdHYp5RwY/BF5Qe0dEXAC8D/CWQjOzRLWn07Pbskn867uAo4AvRMSRwBbgT+YcxhbUFREfkHS0pKdHxIrsfNVxwO0RcfBk9drMrN3UXgSsjgeBfWr+vHd230SeE8CqiLgmu/8idmQwcFCdmbWTFtt0tgI4WNIBVD/gXwu8bsxzLgbeJelbVD+fN0TEw1C95oykJ0bEHcALgVsbNdb8oDoVv8xySg3AUEI42GGL9ktq66H+tUl1+8zbrXDNo30N533q+sPGhwvXpIS5AXQlBpgdvKB4mN7qreuT2toyOFC4Rioefgjp69UHK2nBiSmGE35eto4MJbWV+v5oZxExLOldwE+BTuArEXGLpLdnj58LXAK8DLgb6APeXPNXvBv4uqQeYOWYx/6Eg+rMzDKttuksIi6h+oFfe9+5NV8H8H/q1N4ALJ1oWw6qMzMzB9WZmY1qsTmDUjmozszMHFRnZjaqxTadlSpt2Y6ZmU0reamlu0v6gqRzJC2W9BFJN0u6UNIeDeq27awbGt40+b02M2uCSkRpt1aTd2RwAdWNCg9Q3WzWT3VN61XAufWKaoPqurvmTlJXzcysWfLmDJZExOcAJL0zIs7K7v+cpLc2t2tmZuVqvd/Xy5N3ZFD7+FcL1pqZ2U4i78jgB5LmRMTmiDht9E5JBwF3NrdrZmbl8j6DOiLiQ1lqaYyTWvrqcrpoZmbN5tRSM7OMjwzq2+HU0hSbB/uT6jo6ik9j3LlhbDz4xAyPpKVLbtzaV7gmNTwrJYE0NV1y63BamuW9Wx4pXDOQ2Nbs7t78J42xIeHfC6C3qzupLuV1HCTt9Uj5eUnV25n2elh58t4NwxExEhF9wHappTiozsxs2sj71XFQ0qxsMHBqqZlNa60WYV0mp5aamZlTS83MRrXzBHLhGSRJxa/baGZmLS1vaemisXcB10o6ElBErGtaz8zMStbOEdZ5cwaPAfeNuW8v4HqqMR5PGK9I0jJgGUBP92IcVmdm1tryBoP3Ay8G3h8RNwNIuiciDmhUFBHLgeUAc2Yd0L5DrZntVNp5NVHDOYOI+DTwNuBDkj4jaS7tHexnZjYt5W5RjYhVwGskHQ9cBsxqeq/MzKZAO68myh0MJB0NRERcLOke4ARJL4uIS5rfPTMzK0PRoLqjgStwUJ2ZTUPtPGfQ9KC6md09hTs1VEkLgRMqXNOptLCuzq7i3xekvR6DiaF4c7pnFG8r8bXvTgy46x8eLFyTGqa358zFhWt2nzl2dfXEPNS/Nqluyfy6lxava3VfeSu8RyIthWZuz8xJ7olNtrzBYDgiRoA+SdsF1UlyNpGZTSvtPGeQ92vxoKTRCWMH1ZmZTVMOqjMzy3gHch0OqjMzaw/lXerIzMxaVvHrIpqZTVOVNl5a2vDIQNJxNV/Pl/RlSTdJ+oakJc3vnpmZlSHvNNEZNV9/GngYeAWwAjivXpGkZZKuk3TdwODjO95LM7MSRIn/tZoip4mWRsQR2deflVR3NVFtaumu85/Yet+1mZltJ28w2E3Se6le1Ga+JMUf92t78tnMphXPGdT3RWAuMAe4ANgFQNLuwA1N7ZmZmZUmb5/B6TWppSskHSbpDcDtEXFSOV00MytHK57LL4tTS83MrPmppcMjIzvcyYkaqZTXVupvELPpLVyzdXgoqa2BEhNBU+sGE7634Y60f+d1Q5sK12wa7E9qKzXdMyWBtH9o3KCAXB0dxaf9dpk5L6mtrSNp7+Gyec6gvuGIGImIPmC71FIcVGdmNm3kHRkMSpqVDQZOLTWzac1zBvU5tdTMrA04tdTMLOM5gwIkFb92oJmZtbS8oLozJY1uNFsqaSVwjaT7JB1TSg/NzErSztlEeUcGL89OCQH8G3BiRBwEvJhqcN24aoPqtg5tnKSumplZs+QNBl2SRucVZkbECoCIuBPqL5iPiOURsTQilvZ2p61LNjOz8uStJvo8cImkM4FLJZ0NfBd4Ac4mMrNpJhI3C04HeauJPifpZuAdwCHZ8w8Gvg/8a/O7Z2ZmZZjI9Qz6gE9lQXVPAo4DVkXEzrG/3MxsgiotOLFbFgfVmZlZ84PqzMx2FtHGm87yBoPhiBgB+iRtF1QnaUIzLYOV4cKdSv0H2fCff1O45tQzHkpq677KlqS6Sx+9sXBNb2d3Ulsf3OXZhWv+/fHrktp6fGva69Hb1VO4ZrdZC5LaeqRvfeGalFRVSPu+IC3t9O/3fG5SW19+5OrCNSuv/WJSW/OecmJSnZXHQXVmZhnPGdTnoDozszbgoDozs0w7zxkUv9SRmZlNOxPZZ2Bm1hYcYV2HpOslnSbpwLI6ZGZm5cs7MlgILAAul7Qa+Cbw7YhouB5T0jJgGUBP9yK6uuZORl/NzJqqFaOly5I3Z7A+Iv4pIvYF3kc1l+h6SZdnH/jjqk0t9UBgZtb6JjyBHBFXRcQ7gb2As4BnNa1XZmZTICJKu7WavNNEd469I9uRfGl2MzOzaSBvn8FrJR1d/TJWSDqMamrp7RFxSSk9NDOzpiuaWvoM4HKcWmpm01A7x1Go0bmr7MI246WWzgSuiYin5jWw18InFX51hysjRUsAkFS4JjUELiVQDGDrSPHgs56OtO0gKW0NJb72I5W012Nmd/FAt8W9aZdSfbhvXeGaRb1zktpat3VzUt3SBcVXca/sfySprZT3cN/wuKEEuQYSA/82991T/Id6B+w6/4mljQZrNtxR6veWp+mppWZmO4tWnNgtS95qokFJs7KvnVpqZjZNObXUzCzTznEUTi01MzMH1ZmZjfKcgZmZtbW81NKlWQ7R1yTtI+kySRskrZB0ZIO6ZZKuk3Tdlq3FrztrZjYVKkRpt1aTd2TweeCTwI+BXwPnRcR84NTssXHVBtXN7l04aZ01M7PmyBsMuiPiJxHxTaqRFBdR/eLnwIym987MrETtHFSXNxgMSHqJpNcAIemVAJKOAdK2qpqZWcvJW030dqqniSrAXwDvkHQ+8BDZxWvMzKYL7zOoIyJulPQhoBIRt0taDtwP3BYRvyqlh2Zm1nRFU0uPBq7AqaVmNg2182Uvm55aOnPmfsVTS0eGi5YA0NVZfA9d6kTOnJ7y5s83bu1LqktJcZ3RVTxFFGBgeDCpLiU1djDx/TEz4XvbMjSQ1FaZr+OimWmXln18YEvhmpT3FKT/nA0M3F9qsufsWfuXNhps6bu3pVJL8yaQhyNiJCL6gO1SS3FQnZnZtJH3q/SgpFnZYODUUjOb1jyBXJ9TS83M2oBTS83MMq24GawsDqozM7PcoLo5kj4q6ZYsoG6NpKslvamk/pmZlSZK/K/V5B0ZfB1YSXX38enAfwBvAI6VdEa9otrU0uHhtAuDm5lZefL2GdwYEYfX/HlFRDxdUgdwa0QcmteA9xnsOO8z2J73GWzP+wwmT0/v3qX9yj64ddVOtc9gi6TnAkg6HlgH21YWtdQ3YmZm6fJ+lX4H8EVJBwO3AG8BkLQrcE6T+2ZmVqp2Xk00kaC6d1MNqlsh6TBJ7wVuj4j/KKeLZmbWbEWD6p4BXI6D6sxsGmrf44L800SvZvyguk8B1wAeDMzMpoOcy7L9bryvsz/fMAmXfVtWVt10bWtn6ON0bWtn6ON0fj18m9xb3mqiQUmzsq+bEVSXerW0lLrp2lZqnduaurrp2lZqna+a2AIcVGdmZg6qMzOzqQ+qW15i3XRtK7XObU1d3XRtK7UutS2bRA3jKMzMrD1M9ZGBmZm1AA8GZmbmwcDMzPKXlk4LkmZFxIRzoCX1AIdkf7wjIoaa07PyZPtF3gfsGxEnZ+GDT4yIHzWpvUURsW7MfQdExD0TqO0EllDz/oyI++s89xDg/cB+Y57/ggm0s9c4db/Mqytblhx8cEScn4VEzpnI65jQznOobibdIun1wFHA2RFx32S3lbW3U7z+7aL0CeTszXwysD/bvwneMpk1Wd2zgS9R/eHZV9LhwN9HxDsb1Dwf+C/gXqox3fsAb8x7k0paApwB7BkRL5V0GPCsiPhyo7qafo793r7a4PnPAT7CH3+QVC2JJzSo+TbwW+CkiHhyNjj8OiKOmED/Cn/gSvoV8NKI2Jj9+TDgwoh4ck5b7wY+DDzCHzc2RkQ8tc7zbwTOzb63kZq+/TannbOAE4Fba+oiIo7PqUt9L/YCfz1O3Udz6j4MLKU6cB8iaU/gfyLiOeM89wUR8QtJrxrv74qI7+a0dRNwOPBU4AKqPzt/ExHHNKhJfT2SXn9rnqk4MvgBcBXw/6j54W1CDcBnqV6l7WLYlsL6vJyaTwMviYg7YNsH4Tep2YFdxwXA+cC/ZH++E/g20HAwkPTfwIHADdT8UAB1B4Ps7/xHxnwA5jgwIk6U9LcAEdGniV+p5H+ofuB+sUB7ZwA/lPRy4IlUv5+/m0Dde6h+8K2dYDvDEfGFCT631iuzdsbdS9NA6nvxB8AGqv9mRdr8K+BI4HqAiHhIUr2r2RwD/AJ4xTiPBdBwMKD6WoakE4D/jIgvS3prTk3q65H6+luTTMVgMCsi/rmEGgAi4oExn3l5b9ju0YEgq79T0kQux7VLRFwo6YNZ3bCkifxwLAUOi2KHaBsi4icFng/VaJGZZMGMkg5k4h9KhT9wI+LH2ev2M2Au8FcRcecESh+g+qE5UT+U9E7ge9R8P2NPUY1jJdWd9EU/jFLfi3tHxHEJdYPZB/Tov9vsek+MiA9n/39zQjsAm7L37+uB52VXNMx776e+HqmvvzXJVAwGP5L0soi4pMk1AA9kp2Ai+2B6D3BbTs11kr4EfC37898B102grS2SFvPHD9tnMrEPtd8DuwMPT+C5oy6X9G9Uf9Or/QC8vkHNh4FLgX0kfR14DvCmRo1IWpR9OeEPXEmf449JwALmA38A3iWJiDil8bfGSuAKST8e09Zn6jx/NBbl/TX3BTDuKbOa/vUBN0j6+Zh28vqX+l78taSnRMTNBesulHQesEDSyVQvMPXFvKLsiOxJwLbrs+adkqJ62uZ1wFsjYrWkfYF/y6lJfT1SX39rktLmDCRtovpDKGA21TfAEH883z0vp7ZQTVa3C3A28KKs5mfAexqdgsjO7f4f4LnZXVcBn887nJV0FPA54MlUP+B3BV4dETfl1F1ONSb8Wrb/oah77jSrGSvyJk2zweqZVF+Lq7NYkUbPv4c//puN196ffOBKaphZFRH/ldPmh+vUnd6obqJS+yze6fQAABlsSURBVLcj79+s/lbgIOCerHa0bty5kDG1LwZektX8NCIuy3n+ucAs4Fiq5/1fDVwbEXmnfArbgZ/Ncf8d8t4f1jzegTyJJHVRPT8uJrgKSdK4k3MRceUk963UlSJZmzOprl66I/fJO9bOk4HD2P634EZzLqOnWwYiYiT7cyfQW2TVWcE+7jfe/c14/SXdFBFPrfn/HOAnEfHnOXWjAx5AD9XTOJsjYv5k99FaT+mniep8KP17vaWDNXULgYPZ/gc+b4XPJ4F/BfqpniJ5KvCPEfG1BjVjV+qMtlV3pU5W9xrg0oi4RdJpwFGS/jXn1E3yh37CaYAvAIdnK6reS3US+qtUJx3z2hr93jaNfm/AxyLidw1qXgF8iuqHygGSjgA+OsHVOh8Y53sb96gnO5J4PtXB4BKqV+b7XxpPwAP8nOoR4+bszzOpHjk+O6d/Se/f0Q99SbvVfl8N2qn9YN7uIfJ/8+7P/t+XrT5aC+yR12ZEbJuYzhYXnED1SDKvryk/mwcDn+BPB/GGP2fWRFHyBRSAm6i+oQ8Hfkf1lMyVOTVvA24G1lO97GY/8IsJtHVD9v+/ovrhNx+4MafmdqofKLsBi0dvE/m+sv8/N+vjy4FrJlD3TGAF1Q+lQaoT3Btzas6l+mH3ANW5gJuBL+fUXJ/9/0NUzwlvu6/g93bFRL43qqtm5rP9BZJ+P4G2fga8lerczjHAV4CzGjz/ZqqbJ2/M/rwEuGyi7428+ybj/ZvVHQ/cBWyheqqoAtwy0Z+bIjfg/wILqC5lXU11PupjiX/X73IeT/3Z/F/ghdnruR/VX8A+2ozXw7cJ/luX3mDCh1L2ZptR8+F+KPDdCbT1++z/XwKOy77OGwxyP8Dr1P0u+/8ngNfV3pdTdx3Vc8m/AzqBNwOfyKm5acz/5wBX5dRcCXww+0DaPfsAvblZ3xvVOYntnjfa35y63459LrCiwfOvHa0D5mUf1LdPoJ1fAUfV/PlpwG+a8f4dfd9R/cVi9LU8lpwBvKb2cOBd2e2pBd+XvcD8CT73VTW3VwNn5r0mO/CzOfrvfPPY+3ybmttUrCZKWb42EBEDkpDUGxG3S3riBNr6kaTbqf628o7sFMRATk3KSh2AB7NVHy8GzsomoicU9xERd0vqjOr56/Ml/Y7qB3c9KacBRleKvCUmvlJkVMr3douk1wGd2SmBU4BfT6Ct0XmWh7NTYQ8Bixo8/zpJC6iusPkt1SOs30ygnX8A/kfSQ1QHkN2pvkZ5Ut6/AEMRsVZSh6SOiLhc0r/nFUl6D9VNXaN7BL4uaXn8/+2dabRkVXmGn7elsQVpRAhGXcikiSKgoWlBQ5RB1KUQR4gC0rYDRIwMUQmBEELEqIhDBMGhg8pgIuhSAaMiUZQhTI0tIIQF4rBQASVCtwbRhjc/vn36nltddaaqun3rsp+1at2u07Vrn1NVZw/f8H72qTXtpiUypkiuOtNZOT9hNZF4+fKaNl3vzQfTZ3ebpL8BfkYsajLriHWRgfzHxKB0re3L0qC0e9UPVdKXiBXzkcCexJZ0vu2XNujv8URc/kPJabiR7bsqXt81UmcD4CXESuc2SU8EdrB9cU277xK262VMbenfYPtZFW2OJyKX9gI+RtiWl9k+vqavLQlZg0vS+T7K9qqqNl2vLbU5joiCAfgGcJLtyslY0j5EBNcW6RoXAifavqDBeW4FLHRNBFfp9fMJhz80d/i3/v2mdpcQiVbvBTYD7gEW267zUdxAZLL/Nj3fkFitD4xC0oBERg8Ztinp722/t+dYp3tT0mLCFPg44N2ESfFk21cNc46Z7kxcNFGKvtmYcGj+vua1GxDO0qfYPkTj1+NprSGTBui7CUfrUcS1nW779oZ9PhpYYLsyp0ERo34I8Hjb26bP4uO296pos9D2Sk3lG0zD9YldrXWh2iLplYSN+v70/HHE4PzlBm1byYAMeZ4bErtSEbkrGwPnuibTWtKNxKTxu/R8ATER7VDR5hbaJzLWIul62ztV/H/jezMz+5jJPIPLbe/WJ0qiSZ7BroSzbVV6vhB4hu2ra/psrMcj6SDb50j6237v5cFJT0X7xhoyPe02BB5wqjFdFeKoIbRnJK0AnkP4RP4sHbuxZlC5yPY+6p9vYFdrIbXShZJ0tO2TNT1prdxZ31WtpBW936ek7xXXWHF+rVbPw/x+hyH9HpcQCX8Qu4vP2B5oYpJ0PnC47TaJjE3Ope/n2mYRJOkjto+UdCH9v+esTbSOmDGfge3d0t9BuipVnEGE8BX8ps+xfrTR4ynS/LucH7TTkCnTJsTxBXTXnnnQ9u+Ly1fkRFSuBGzvk/5uXfW6AbTVhSoyw5tke5fp57to8rtuJQPS9fc77CRi+0OSLmUqCXKpB4T0lgbYjYCbJTVOZGzIWp9VeRFEaHPNJ7L3By2Czk5/TxnyXDIjZkYdyGnV+wPbT2/btHzT2n44DWZ1NNbjsf2J9LdrpmtjDZkeFtguJgJs/ybtYPqd4wnpbxftme9IOhZ4jCKj9TDgwiYNJf1Xrzmp37E+59tYF8r2helv2wzU6yR9iPCdQIR6ViqWJrrIgABrfseNJLaHXAQVbACsKlbeGiwFfgoxybyf2EGsOeV0bFj6LaRaLYKc1GQ94qTKzPDM6GTgcOLeKukpg26eAdwh6XBiNwAxkN3RoN0JtNfj2YaQsNiVmET+m0hUq+uvk4YMoWm0k1O0kqRFTEUL9Z5bXxNWQY0p6xgifv9G4FAiQWtZ1fsl+/QGwGaKxKJiMFgIPLmqLS11oQaZDQoqVrVvJ+LqP5+ef5OYEOrYjA6rZw2Q2CYSGqvabQvcaftBhUz6jsBZtu+radd45V0MsJLm9w62aVE0LOf3OdZqEZR8IFXfc608R2Y8rItoou8SK4lriAQcoFaLZ3Pgo0S0ggnTypG272nQX1s9nquIVea/p0OvBd5ue5cGfbXSkEltFgP/QYRQrglxdB89fg3Q7SkYYlcz6NyOIKJEnpTOr2Al8Cnbp1W0baULpSlZjlcRn0GRJf464G7bRw1xKVX9TaNuxSrpdmCXOsdvn3YriEF9K2Ii/grwTNdH3awgrbxLvp4b+g2akt5KLJS2IcQBCzYCrrB9UE1fXWqNvJPIPt6biJR6I/A5Dwh91QBZjlJfY5NHyVSzLiaDTjfhEP21qqbU70aT9H1XhHr2vHZhT19NIm5ahzi2RR0K4pTavn3QzT3g9Y8iHJgf7nCe19neucGxoR2R6hBqqwg93tv26ibXU2p3ve2dJL2LiM0/taGj+xrbzym1HxhaKmljYBNiUD6m9F+rGv4OryTCensLBX2xpl3rRVBm9jHjSWdtBv2uESal9kU1pR8wfUtfpZvyNUnHEKt1p/b/qRReOeimknQocCIRPvgwabBlgJRyqd3biBDDm9LzTSS9zvbpfV47zOfRuiCOUvQSkXS2VgSTB0QvJXPgAYQTuS0bStqmMMtJ2pop536ZoRyRKoXaElFFTyZkPir9ILSX2C74QwpkWMJUAECTZLXG5kdHeO39xG6qC61qE6RJ/xLbexDmucYoIgRPBZ5BhFU/CvhtnUM9Mz5mbDLoGFXRNcKkoEs1pf3T30N7jr+W6sH9ncD2dWaoPrzFduH8xPav002/1mTAcJ9Hl4I4w0QvXS7pNMKWXzYH1mVyH0UMtncQv40tWfu7GIUj8m2kUNv0Prclc2QdP02P9dOjKUuBvwbeY/tHaZI7u6YNtk9JK++VxO7xH8e48m5VmyBN+g9L2tg1eS59OI24p84nzGcHM1V3PLMOmIikM0kL3JO5KmmzBvb/rwH7laN1xoWkrwOvcssEq+RQ27GIlkqrrRtsP7OizV8Q+RIPlY7tVDXQSnofsfpqJbOhkAx4je3zGl5S0a7I5C5+YMWk36RQ/aMJjRsInaGBk7k6ql9Kutr2LoWpRhGddv1MODCTM34L19e6KK+8x4461CaQ9BXCp/FNpk/6dbv262zvXDbLNjGbZcbHutAm6sI1kg5xSlWX9GpiAKhbSTSupqQhi4kTWkJXSrq6rq8evg58PpkCIFbBX69p8w3gWkn7lZzoy6jOuygc4GXbuwmn/EAcYbxHA60mA+AipieqGVgp6dm2V9S0XcSUE/NZqtbV+TQR3fNhQvxtKc00ob6jDqG2aimxXWp3KaFcuh5hqrtH0hW2B0aIDbnyboUkEQ7tNlF+EIuLunujH/8naX3i/jyZCPFtpOWVGQ+TsjPYgZAyvpSIbNkUeLPtO2vaLel33H1i2SWdaPsESZ/u32RwREVqfw0hy3sjU/6J2rj5tPI+lClb9TcJnaGBdn2FkN3xhNDcm2xfOc5VVdpV/Iq1TT4DnZKSPkdMPBcQE8I+hFzxVkRm9skD2rXNDF5ue5FK2dTFsZprmkeE2q5xfBKfe+UNIeli4nN4J2H2WQL8ss7WXtqBvJnYFZwwKCqop12nlXcXVJORXtFufaYWZk01nvrJsHzM9g8rG2bGxkRMBgCSXkHYWFcBz3dD7Z6ZYpjBON1Mf0qsnmtvplJkydOIgelMQo20MiNb3erioik5imlUmWIUIcQvLUx0impbXyUE75bb3m5Au1a6OikCZjfgC4R/42fA+2wPVM5M5pezbB/YpI+etsXkUzZvXGt7cU27G4mJ57PAcbavbTgZNF7QDIukzwKn2b62RZvdiWv6MTGpbgEscX1xmyNs/2vdsczMMRFmIkn/RqwWdyRWIBdJOrXseO15/Xm299eABJd+N6CGS+iCiEI6hDA1VBaN7+l3d3puJkl1N5PSe9+mkHg4k/qkp751casvaQ3bEWaU3YjP8zIi8qaKzZme7f0H4Am2H5BU5dBvmxl8BHFdhxPql3sSq/WBJPPLlpLWd3tBtbYS2wX/TOw+Lk8TwTZEbYk6vkCf8pwtz7kpuwAHSvoJsQtpUqf5g8CLnEqbSvoTIkencmdGfEe9A/8b+hzLzBATsTOQdCRRr7dwsm4MfMgDCnxLeqLtX6hF3VkNmdCVVs99mtU6MpcTBWOm3Ux1Zo4+71OZ1a2OdXFT2/OIaJZz06EDiIIp+1e0OZ6QKvhKOrQvYTL6IPDJQavy5Hh+NjFRjVJXp7efs4iwxguYbn6pEyTsLLHd8TyvAl7Ys8O62DXS1x37any/lNr0y8sZuONRhNceQCwsLiv910bAw66ROMmMj4mYDAA0Q8XVZ5q2N1P6/wWEvbvX5FOVKVpEz1xFZPneS+hEPbXBOd7ca9bpd6xPu52Zkk24wnZtSKxaJiWmPo5j7cTCQYPR2bZfL+k++uRB1E36XUm+qH671DpfVD9V1rWOjQq1lGGXdCbhIysyxg8ixpVBC7Utga3pkxhHRNG1SubLjI5JMRN1La7+KkKga3NiyzswVE5DJril99ietUMc6/Txr5O0jKmb6UDq8wjOJmo1v5gwPxxIhe5P4iKF1v8HCFEx00w7CeB6Sbt6KpprlwbnSBr8W+VEDBr0KzgXeBc9jvsKFinkxX9KrOxboSntquem/ppqV5VraCwgdk0/H/DaMo21q4ZF7RVIIUyUzyHMdBCr/YHmr7TL+Anx+WVmE54FtTfrHnQvrn47UfegSR/3pr9HEvbMaY8G7U8gCoLfTdxIdwFfaNDu0UQBniJE7yiinkFVm6KOblEDeT6p5nDDa21UF5cYYG8gJpqHCb/Gj9K/bx7xd3x5+ruKMEkVj1XAyrp2Lfo5PF3P74hs4uLxI+COBu2vAl5PLKTWI1bCretmE2GUVzZ43WJCZ+gyIlrtdmDRKD/7Ul8riAVT47rVxMJih9Lz11V9Hl2/5/wY/2MidgZE/dj7NV0Ouckq8G7bdSvmNa9NK8alwO7QV663itcQhcu/Z3uppCcwtdrvS3IGnumwn9c5qMsUTsz70m7kLmL3U9XXAqY7gS+XdIary1Du0+KchsLdpZ5PSDur3lySQVIZHwU+mq79rR1OdQPb5czhcxR6Q215GjXfGYDD2fx0BmhXSdrbo8tI7iLD/hqilvQBwPOJTOIXDXrxEN9zZsxMymTQqri6phLHrlNUO/sy9QPFGcSAsg3T9fAbaQyRqpVJWq0Qq7uHcDIOxN2jWj6pyGL9B8IB+lgi76CKs4jVV2EaOYAwN+1XcX6ToCC5lMhWns90/anKRKiOEwF00K5SrGIeYqqAEcQE3kgHKA3+Nw347/fTUheogtYy7LbvSE7hLxOmtxfZHosZKzNeJsKBrP7F1d/tATIFmkocK2fAFtjVjtZOK0ZJpwPHEnor7yBu/BWuKUTTNqpF3eUhOjmBZzuSbnVFTsEY+is7U8tSG1ARPSbpJtvbj+F8RppsqIYKpH3CtjcnRPIehFyXYBKZlJ3BdulR2GlfTqT29/3BFQNwSqI5wqmASFpNf7Cqo64rRk/V9v24QqdooWu0ZxI/TI95NCi56e7yEJ2cwBPAlZK2s33zDPX3d0TB95UpfHYnYmFSJ8C3XNJit0joashIV3Np8G+y05gxE2JmZpiUncGtRPr/TUyXeqg0Y/RbNY16JdXz3q1qJ/S0fWx6fa2onrrJQ9xC2J2LXISnALcCq6lPLJq1pOvalnAAP0izRKlh+ivyNHYjktxOIZREK4sfSfof4KlEJE3ThK4m53O9azLPW7xX4+i7zNxjUnYGv3SqkduSeZI2sf1rgGTXHcs1a6p2ws2UNHWorp1QhKOeTcpilfQr4GDbP6ho9lfpvQ/rOV7l13hJ1XlMMDN9XcV3+zKi2ttXJZ3UoN2Lx3Q+Px7he50M7Nsi6CIzh5iUncFeRMhao4iRUruDCTt+Ubt1P0JPvlZHvsM53kpIUbepnVBo6xxn+9vp+e7Av7giwzQl4K0lD9HEcafQ7C/nQbRVqZyVzNR1SbqI0D/amzARPQBc44aV8Dr2+TzWLkVZl7/SpZ8rbFflFGTmMJMyGZxDRIxMq1hW5Qgutd2OKZnmb43LtqyOtRPUp6Rmv2M9/99FHuIvCX/Jk4hIpy2BW1xRN2ESmOnrSsEMLwFudGhDPZGIs794TP21UnHt2EcRffcCQheqSfRdZo4xKZPBjEaMdEHSF4k8g9raCT3tvkQk7hS7lYOIpKJXVrRpHRkk6fvEpHiJQ0p5D+AgD5ANmBTm6nUVqKWKa8c++sm2FzRadGUmn0nxGcx0xEgXLkiPMk1u4DcStZOLouOXEbHzVXSJDPqD7XslzZM0z/a3JX2kwfnNdubqdRW0VXFtTSn67s9tX1H+P0nZbPQIYVImg12JikgzEjHSkce5jz57g3bbEslp84jvYy9ipdtPZruI7Z5PTJA/Tc+3JLSKqrgvRSxdBpwr6R5KkUgTzFy9roLNgJsVxZPGpuKaOJW1q+X1O5aZg0yKmai1tO5M0y/Er0kYa5uw2UGfQ1WbUtsNCD0eEaaohcC5VeGok8Bcva4CtVRx7djHc4HnEbpcZSXXhcArx+kcz8weJmJnMJsG/V40pc++taSymWgjoMmA1DhstsvnIOlyhx7M3aydMXuSpP8FPmD79LbvvS6Zq9fVyygH/QrWJyRN1mN64uNKQnso8whgInYGsxkNqc/eNWx2VEjalFDPnNUO+rbMleuStIqpyW59wkT423EkgknacjYvvDLjJU8GIyRNDE+zfUnKBVjP9qqaNp3DZkeFUmW4mepvpphr1yVJhBTLrraPqXt9h/f/Nv1reezZ5+WZOUaeDEaEQuXxEODxtrdVqKt+3DVl/CYhbDYzuxiXpIqicE7BAuDVwGrbR4+6r8zsYyJ8BhPC24iKT1fDmmL1tXr1TEbYbGYdUUoIg4g425lwmI8c28t7Dl2RopgyjwDyZDA6HrT9e6UCPJLWo1mewSSEzWbWHfuW/r2a0CJ6+Tg6StpdBfOARUSFwcwjgDwZjI7vSDoWeIxCE/4woEmU0FwVkMuMANfUwxgxy5mqAbKaUIKdE5ncmXqyz2BEKIrOvIlSYRBg2ThlBDJzF0lH2z5Z0qmsvcM0EbZ8ju0fzvzZZeYieTLIZGYhkva1faGkJQNesimwZJQJYZLmA28lahkDXAp8wqWay5m5S54MhkTSebb319plAIFc/i8zPiQdavsTI3y/ZUQew2fTodcDD9l+86j6yMxe8mQwJEUsu6R3AFcBd5b/PyfxZIZB0h8RpTa3Y3q9hpHH/neRU8/MHeat6xOYdEpJTY8FPgmcQ0SA/C5PBJkRcC5wC5HlfiIRTTTqOsoFD0natngiaRumaihk5jh5ZzBiJO1IlKV8NXCn7Reu41PKTDCSlttepFR7OR271vbiMfS1J/AZ4I50aCtgaVGFLzO3yaGlo+ce4C7gXqKweCYzDIXz9heSXgb8nFQvewxsCmxPTAKvAJ4L3D+mvjKzjGwmGhGSDpN0KSE4tynwluw8zoyAkyRtDLyDkDpfRkhNj4Pjba8kpKv3AE4DzhhTX5lZRp4MRscWwJG2n2n7n7K8RGZE7EeYc2+yvQewNzCwJOqQFP6BlwGfsv1VQik18wgg+wwymVlMP1G6MQrVXQT8jJhwdgIeAK7J0USPDPLOIJOZ3cyTtEnxJOkHjcvXtz+ROf9i2/cRvol3jamvzCwj7wwymVmMpIOBY4Hz06H9gPfYPnvdnVVmLpIng0xmliNpO6BIMvtW9kdlxkGeDDKZTCaTfQaZTCaTyZNBJpPJZMiTQSaTyWTIk0Emk8lkyJNBJpPJZID/B98FvjZEXNqxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23dd3c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_matrix(compute_topic_cuisine_matrix(LDA_model_three, corpus2, recipes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
